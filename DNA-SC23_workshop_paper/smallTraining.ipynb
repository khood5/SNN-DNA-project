{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "from torch import nn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dnaDataloader import expermentDataloader\n",
    "from dnaDataloader import addData\n",
    "from dnaModelUtil import train\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "batch_size = 25\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   mp.set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "   pass # throws error if run twice without resetting the kernal, if its already set we dont care that this errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval with small traing sets\n",
    "The goal here is to eval the model while training on small sets of data. That is how well can MLP learn from 100-200 examples of single-molecule experiments.\n",
    "A verity of samples have been provided anf preprocessed (converted from excel to csv and had empty frames added) to the folder <pre>/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [d[0] for d in os.walk(\"/users/kent/student/khood5/GitHub/SNN-DNA-project/Prepocessing/sorted\")][1:] # remove first one is it is \"/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted\"\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "featIn = 0\n",
    "for d in folders:\n",
    "    data = expermentDataloader(\n",
    "        f\"{d}/index.csv\",\n",
    "        f\"{d}\", \n",
    "    )\n",
    "    rawData = [d for d in data]\n",
    "    featIn = len(rawData[0][0])\n",
    "    trainValidData = []\n",
    "    testData = []\n",
    "    addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "\n",
    "    np.random.shuffle(trainValidData)\n",
    "    trainData = []\n",
    "    validData = []\n",
    "    addData(trainData, validData, trainValidData, rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "    datasets.append({\"name\": f\"{os.path.basename(d)}\", \n",
    "                     \"train\":DataLoader(trainData, batch_size=batch_size, shuffle=True) , \n",
    "                     \"valid\":DataLoader(validData, batch_size=batch_size, shuffle=True) , \n",
    "                     \"test\":DataLoader(testData, batch_size=len(testData), shuffle=True) ,\n",
    "                     \"model\": {}}\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets:\n",
      "{'name': '50_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f995a4ffc70>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f995a4ffbe0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f9aa8b8a500>, 'model': {}}\n",
      "{'name': '1200_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f9aa8be0760>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f995a4e53c0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f995a4e5780>, 'model': {}}\n",
      "{'name': '800_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f995a53c1f0>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f995a523c70>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f995a584250>, 'model': {}}\n",
      "{'name': '1800_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f995a5843d0>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f995a53de70>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f9953960250>, 'model': {}}\n",
      "{'name': '100_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f995a584070>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f995393c3d0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f9953997f40>, 'model': {}}\n",
      "{'name': '400_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f9953994220>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f995393c370>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f99539a6c50>, 'model': {}}\n",
      "6\n",
      "featIn: 12000\n"
     ]
    }
   ],
   "source": [
    "print(f\"datasets:\")\n",
    "for d in datasets:\n",
    "    print(d)\n",
    "print(f\"{len(datasets)}\")\n",
    "print(f\"featIn: {featIn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 50_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1200_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 800_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1800_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 100_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 400_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    print(f\"-- {d['name']} --\")\n",
    "    print(f\"train: {len(d['train'])}\")\n",
    "    print(f\"valid: {len(d['valid'])}\")\n",
    "    print(f\"test : {len(d['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = mp.Manager()\n",
    "return_dict = manager.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Process name='Process-2' parent=3469115 initial>,\n",
       " <Process name='Process-3' parent=3469115 initial>,\n",
       " <Process name='Process-4' parent=3469115 initial>,\n",
       " <Process name='Process-5' parent=3469115 initial>,\n",
       " <Process name='Process-6' parent=3469115 initial>,\n",
       " <Process name='Process-7' parent=3469115 initial>,\n",
       " <Process name='Process-8' parent=3469115 initial>,\n",
       " <Process name='Process-9' parent=3469115 initial>,\n",
       " <Process name='Process-10' parent=3469115 initial>,\n",
       " <Process name='Process-11' parent=3469115 initial>,\n",
       " <Process name='Process-12' parent=3469115 initial>,\n",
       " <Process name='Process-13' parent=3469115 initial>,\n",
       " <Process name='Process-14' parent=3469115 initial>,\n",
       " <Process name='Process-15' parent=3469115 initial>,\n",
       " <Process name='Process-16' parent=3469115 initial>,\n",
       " <Process name='Process-17' parent=3469115 initial>,\n",
       " <Process name='Process-18' parent=3469115 initial>,\n",
       " <Process name='Process-19' parent=3469115 initial>,\n",
       " <Process name='Process-20' parent=3469115 initial>,\n",
       " <Process name='Process-21' parent=3469115 initial>,\n",
       " <Process name='Process-22' parent=3469115 initial>,\n",
       " <Process name='Process-23' parent=3469115 initial>,\n",
       " <Process name='Process-24' parent=3469115 initial>,\n",
       " <Process name='Process-25' parent=3469115 initial>,\n",
       " <Process name='Process-26' parent=3469115 initial>,\n",
       " <Process name='Process-27' parent=3469115 initial>,\n",
       " <Process name='Process-28' parent=3469115 initial>,\n",
       " <Process name='Process-29' parent=3469115 initial>,\n",
       " <Process name='Process-30' parent=3469115 initial>,\n",
       " <Process name='Process-31' parent=3469115 initial>,\n",
       " <Process name='Process-32' parent=3469115 initial>,\n",
       " <Process name='Process-33' parent=3469115 initial>,\n",
       " <Process name='Process-34' parent=3469115 initial>,\n",
       " <Process name='Process-35' parent=3469115 initial>,\n",
       " <Process name='Process-36' parent=3469115 initial>,\n",
       " <Process name='Process-37' parent=3469115 initial>,\n",
       " <Process name='Process-38' parent=3469115 initial>,\n",
       " <Process name='Process-39' parent=3469115 initial>,\n",
       " <Process name='Process-40' parent=3469115 initial>,\n",
       " <Process name='Process-41' parent=3469115 initial>,\n",
       " <Process name='Process-42' parent=3469115 initial>,\n",
       " <Process name='Process-43' parent=3469115 initial>,\n",
       " <Process name='Process-44' parent=3469115 initial>,\n",
       " <Process name='Process-45' parent=3469115 initial>,\n",
       " <Process name='Process-46' parent=3469115 initial>,\n",
       " <Process name='Process-47' parent=3469115 initial>,\n",
       " <Process name='Process-48' parent=3469115 initial>,\n",
       " <Process name='Process-49' parent=3469115 initial>,\n",
       " <Process name='Process-50' parent=3469115 initial>,\n",
       " <Process name='Process-51' parent=3469115 initial>,\n",
       " <Process name='Process-52' parent=3469115 initial>,\n",
       " <Process name='Process-53' parent=3469115 initial>,\n",
       " <Process name='Process-54' parent=3469115 initial>,\n",
       " <Process name='Process-55' parent=3469115 initial>,\n",
       " <Process name='Process-56' parent=3469115 initial>,\n",
       " <Process name='Process-57' parent=3469115 initial>,\n",
       " <Process name='Process-58' parent=3469115 initial>,\n",
       " <Process name='Process-59' parent=3469115 initial>,\n",
       " <Process name='Process-60' parent=3469115 initial>,\n",
       " <Process name='Process-61' parent=3469115 initial>,\n",
       " <Process name='Process-62' parent=3469115 initial>,\n",
       " <Process name='Process-63' parent=3469115 initial>,\n",
       " <Process name='Process-64' parent=3469115 initial>,\n",
       " <Process name='Process-65' parent=3469115 initial>,\n",
       " <Process name='Process-66' parent=3469115 initial>,\n",
       " <Process name='Process-67' parent=3469115 initial>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processes = []\n",
    "devices = [torch.device(\"cuda:0\")]\n",
    "epochs = 10000\n",
    "for error_margin in range(10,21):\n",
    "    for d in datasets:\n",
    "        processes.append(mp.Process(target=train, args=(d[\"train\"], d[\"valid\"], f\"{d['name']}_{error_margin}\", featIn, return_dict, epochs, error_margin, devices[0])))\n",
    "        devices.append(devices.pop(0))\n",
    "    \n",
    "processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 50_nM_AR_600_10 on cuda:0...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m         processes[i]\u001b[39m.\u001b[39mstart()\n\u001b[1;32m      8\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m run:\n\u001b[0;32m----> 9\u001b[0m         processes[i]\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m     10\u001b[0m         processes[i]\u001b[39m.\u001b[39mterminate()\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(return_dict)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpoll(os\u001b[39m.\u001b[39;49mWNOHANG \u001b[39mif\u001b[39;49;00m timeout \u001b[39m==\u001b[39;49m \u001b[39m0.0\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mwaitpid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpid, flag)\n\u001b[1;32m     28\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[39m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[39m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "processesList = list(range(len(processes)))\n",
    "\n",
    "while processesList:\n",
    "    run = processesList[:1]\n",
    "    processesList = processesList[1:]\n",
    "    for i in run:\n",
    "        processes[i].start()\n",
    "    for i in run:\n",
    "        processes[i].join()\n",
    "        processes[i].terminate()\n",
    "print(return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict(return_dict)\n",
    "with open(\"./Models/smallTrain/results.json\", 'w') as file:\n",
    "    json_object = json.dumps(results, indent=4)\n",
    "    file.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
