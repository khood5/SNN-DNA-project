{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dnaDataloader import expermentDataloader\n",
    "from dnaDataloader import addData\n",
    "from dnaModelUtil import MLPModel\n",
    "from dnaModelUtil import train\n",
    "from dnaModelUtil import progress_bar\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "defultePlotSize = plt.rcParams['figure.figsize']\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "folder = '/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted/1800_nM_AR_5000'\n",
    "oneMinInFPS = 1200\n",
    "batch_size = 10\n",
    "num_workers = 0\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneMinInFPS*((1/oneMinInFPS)*10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making graphs for short movie length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDatasets(length: int, folder: str):\n",
    "    length = int(length*oneMinInFPS)\n",
    "    assert length > 0\n",
    "    data = expermentDataloader(\n",
    "        f\"{folder}/index.csv\",\n",
    "        f\"{folder}\",\n",
    "        length=length\n",
    "    )\n",
    "    rawData = [d for d in data]\n",
    "    trainValidData = []\n",
    "    testData = []\n",
    "    addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "    np.random.shuffle(trainValidData)\n",
    "    trainData = []\n",
    "    validData = []\n",
    "    addData(trainData, validData, trainValidData,\n",
    "            rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "    trainDataset = DataLoader(trainData, batch_size=batch_size,\n",
    "                              shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    validDataset = DataLoader(validData, batch_size=batch_size,\n",
    "                              shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    testDataset = DataLoader(testData, batch_size=len(\n",
    "        testData), shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    # print(f\"Training dataset size: {len(trainData)}\")\n",
    "    # print(f\"Valid dataset size: {len(validData)}\")\n",
    "    # print(f\"Testing dataset size: {len(testData)}\")\n",
    "    # print(f\"Total: {len(trainData) + len(validData) + len(testData)}\")\n",
    "    # print(f\"number train batches:{len(trainDataset)}\")\n",
    "    # print(f\"number valid batches:{len(validDataset)}\")\n",
    "    # print(f\"number test batches:{len(testDataset)}\")\n",
    "    return trainDataset, validDataset, testDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasests = {}\n",
    "maxLength = 3*oneMinInFPS\n",
    "minLength = 1/oneMinInFPS\n",
    "step = (1/oneMinInFPS)*10000000\n",
    "total = len(np.arange(minLength, maxLength+step, step))\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [------------------->] 100%\n"
     ]
    }
   ],
   "source": [
    "datasests = {}\n",
    "current = 0\n",
    "for length in np.arange(minLength, maxLength+step, step):\n",
    "    datasests[f\"{length}\"] = makeDatasets(length, folder)\n",
    "    current += 1\n",
    "    progress_bar(current=current, total=total, bar_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, target = next(iter(datasests[\"0.0008333333333333334\"][0]))\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = datasests[f\"{minLength}\"][1]\n",
    "train_data = datasests[f\"{minLength}\"][0]\n",
    "print(f\"val_data: {val_data}\")\n",
    "print(f\"train_data: {train_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(next(iter(train_data))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dir = \"/home/khood/GitHub/SNN-DNA-project/Models/modelsForVariedLengthed\"\n",
    "em = 5\n",
    "epochs = 10\n",
    "# train(\n",
    "# trainData: DataLoader, validData: DataLoader, name: str, savePath: str,\n",
    "# model, lossfunction, optim, return_dict: dict, epochs: int, margin_of_error=20, device=torch.device(\"cpu\"), printStatus=False)\n",
    "resultes = {}\n",
    "return_dict = {}\n",
    "current = 0\n",
    "keys = list(datasests.keys())\n",
    "while keys:\n",
    "    length = float(keys.pop(0))\n",
    "    val_data = datasests[f\"{length}\"][1]\n",
    "    train_data = datasests[f\"{length}\"][0]\n",
    "    # next(iter(train_data))\n",
    "    featIn = len(next(iter(train_data))[0][0])\n",
    "    # print(f\"featIn: {featIn}\")\n",
    "    model = MLPModel(featIn=int(featIn), capacity=1000)\n",
    "    model = model.to(device)\n",
    "    MSE = nn.MSELoss(reduction='mean')\n",
    "    adam = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=1e-5)\n",
    "    resultes[f\"{length}\"] = train(trainData=train_data, validData=val_data, name=f\"{length}_min(s)\", savePath=model_dir, margin_of_error=em,\n",
    "                                model=model, lossfunction=MSE, optim=adam, return_dict=return_dict, epochs=600, device=device, printStatus=False)\n",
    "    current += 1\n",
    "    progress_bar(current=current, total=total, bar_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultes[list(resultes.keys())[0]].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = []\n",
    "acc_data = []\n",
    "loss_data = []\n",
    "for min in resultes.keys():\n",
    "    header.append(min)\n",
    "    acc_data.append(resultes[min][\"accuracy_val\"])\n",
    "    loss_data.append(resultes[min][\"loss_val\"])\n",
    "\n",
    "acc_data_df = pd.DataFrame(acc_data, index=header).T\n",
    "loss_data = pd.DataFrame(loss_data, index=header).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [60, 25]\n",
    "sns.set(font_scale=2)\n",
    "ax = sns.lineplot(data=acc_data_df)\n",
    "sns.move_legend(\n",
    "    ax, \"lower center\",\n",
    "    bbox_to_anchor=(.5, 1), ncol=10, title=\"accuracy vs movie length 1-20 minutes\", frameon=False,\n",
    ")\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.1)\n",
    "ax.set(xlabel=\"epochs\", ylabel=\"accuracy\")\n",
    "vals = ax.get_yticks()\n",
    "ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "# ax.set(title='accuracy vs movie length 1-10 minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc = pd.DataFrame(acc_data_df.max()).T\n",
    "max_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = list(sorted_value_rnn_valid_acc.keys())\n",
    "# values = list(sorted_value_rnn_valid_acc.values())\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [30, 15]\n",
    "a = sns.barplot(data=max_acc)\n",
    "a.set(xlabel=\"length in seconds\", ylabel=\"accuracy\")\n",
    "vals = a.get_yticks()\n",
    "a.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "vals = a.get_xticklabels()\n",
    "a.set_xticklabels(['{:,.1}'.format(float(x.get_text())) for x in vals])\n",
    "a.set(title='accuracy vs movie length 1-20 minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/khood/GitHub/SNN-DNA-project/Models/mlp_1frame_1min_acc.json', \"w\") as f:\n",
    "    json.dump(resultes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [40, 500]\n",
    "graph = 1\n",
    "fig = plt.figure()\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.3)\n",
    "# fig.tight_layout()\n",
    "j = 1\n",
    "for key in list(resultes.keys())[:1]:\n",
    "    plt.subplot(2*j, 2, graph)\n",
    "    plt.title(f'{key} min(s) accuracy vs epochs training')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.plot(list(range(len(resultes[f\"{key}\"][\"accuracy_val\"][:]))),\n",
    "             resultes[f\"{key}\"][\"accuracy_val\"][:], '-', color='black', )\n",
    "    graph += 1\n",
    "    plt.subplot(2*j, 2, graph)\n",
    "    plt.title(f'{key} min(s) losse vs epochs training')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(list(range(len(resultes[f\"{key}\"][\"loss_val\"])))[\n",
    "             :], resultes[f\"{key}\"][\"loss_val\"][:], '-', color='black')\n",
    "    graph += 1\n",
    "    j += 1\n",
    "# plt.suptitle(\"test\")\n",
    "plt.rcParams['figure.figsize'] = defultePlotSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
