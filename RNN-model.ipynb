{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch\n",
    "import copy\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from dnaDataloader import expermentDataloader\n",
    "import os\n",
    "import random\n",
    "import matplotlib.colors as mcolors\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from dnaModelUtil import printStats\n",
    "from dnaModelUtil import averageDiff\n",
    "from dnaDataloader import addData\n",
    "from dnaDataloader import expermentDataloader\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from torchsummary import summary\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "oneMinInFPS = 1200\n",
    "batch_size = 10\n",
    "num_workers = 0\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 200\n",
      "Valid dataset size: 100\n",
      "Testing dataset size: 588\n",
      "Total: 888\n",
      "number train batches:20\n",
      "number valid batches:10\n",
      "number test batches:1\n"
     ]
    }
   ],
   "source": [
    "folder = '/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted/1800_nM_AR_5000'\n",
    "oneMinInFPS = 1200\n",
    "data = expermentDataloader(\n",
    "    f\"{folder}/index.csv\",\n",
    "    f\"{folder}\", \n",
    "    length = 10*oneMinInFPS\n",
    ")\n",
    "# rawData = [([np.array([e]) for e in d[0] ], d[1]) for d in data]\n",
    "rawData = [d for d in data]\n",
    "featIn = len(rawData[0][0])\n",
    "trainValidData = []\n",
    "testData = []\n",
    "addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "\n",
    "np.random.shuffle(trainValidData)\n",
    "trainData = []\n",
    "validData = []\n",
    "addData(trainData, validData, trainValidData, rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "trainDataset = DataLoader(trainData, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) \n",
    "validDataset = DataLoader(validData, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "testDataset = DataLoader(testData, batch_size=len(testData), shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "print(f\"Training dataset size: {len(trainData)}\")\n",
    "print(f\"Valid dataset size: {len(validData)}\")\n",
    "print(f\"Testing dataset size: {len(testData)}\")\n",
    "print(f\"Total: {len(trainData) + len(validData) + len(testData)}\")\n",
    "print(f\"number train batches:{len(trainDataset)}\")\n",
    "print(f\"number valid batches:{len(validDataset)}\")\n",
    "print(f\"number test batches:{len(testDataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featIn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before adding RNN just convert current Sequential model to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, featIn, capacity):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(featIn,capacity)\n",
    "        self.inputAct = nn.Tanh()\n",
    "        self.inputDropout = nn.Dropout(p=0.2)\n",
    "        self.hidden1 = nn.Linear(capacity,capacity)\n",
    "        self.hidden1Act = nn.Tanh()\n",
    "        self.hidden1Dropout = nn.Dropout(p=0.2)\n",
    "        self.hidden2 = nn.Linear(capacity,capacity)\n",
    "        self.hidden2Act = nn.Tanh()\n",
    "        self.output = nn.Linear(capacity,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.inputAct(self.input(x))\n",
    "        x = self.inputDropout(x)\n",
    "        x = self.hidden1Act(self.hidden1(x))\n",
    "        x = self.hidden1Dropout(x)\n",
    "        x = self.hidden2Act(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel(featIn=featIn, capacity=int(featIn*0.06))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "        epoch: 9/10\t         Train Loss:5779.4847 Valid Loss:4357.1726\t         Train accuracy:0.24 Valid accuracy:0.23         \u001b\u001b\r"
     ]
    }
   ],
   "source": [
    "MSE = nn.MSELoss(reduction = 'mean')\n",
    "adam = torch.optim.Adam(model.parameters(),lr=0.0001,weight_decay=1e-5)\n",
    "\n",
    "em = 20\n",
    "epochs = 10\n",
    "losses = []\n",
    "accs = []\n",
    "print(\"training...\")\n",
    "for e in range(epochs): \n",
    "    avgLossTrain = []\n",
    "    currentAccTrain = []\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(trainDataset):\n",
    "        inputs, targets= inputs.float().to(device), targets.float().to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = MSE(outputs, targets)\n",
    "        avgLossTrain.append(float(loss.item()))\n",
    "        adam.zero_grad()\n",
    "        loss.backward()\n",
    "        adam.step()\n",
    "        totalCorrect = torch.sum(torch.isclose(outputs.int(), targets.int(), atol=em))\n",
    "        totalCorrect = totalCorrect.item()\n",
    "        currentAccTrain.append(float(totalCorrect/len(targets)))\n",
    "        \n",
    "    avgLoss = []\n",
    "    currentAcc = []\n",
    "    model.eval()\n",
    "    for i, (inputs, targets) in enumerate(validDataset):\n",
    "        inputs, targets= inputs.float().to(device), targets.float().to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = MSE(outputs, targets)\n",
    "        outputPlot = outputs.clone().detach().cpu().numpy()\n",
    "        targetsPlot = targets.clone().detach().cpu().numpy()\n",
    "        avgLoss.append(float(loss.clone().detach().cpu().numpy()))\n",
    "        totalCorrect = torch.sum(torch.isclose(outputs.int(), targets.int(), atol=em))\n",
    "        totalCorrect = totalCorrect.clone().detach().cpu().numpy()\n",
    "        currentAcc.append(float(totalCorrect/len(targets)))\n",
    "        print(f\"\\\n",
    "        epoch: {e}/{epochs}\\t \\\n",
    "        Train Loss:{'%.4f' % (np.sum(avgLossTrain)/len(avgLossTrain))} Valid Loss:{'%.4f' % (np.sum(avgLoss)/len(avgLoss))}\\t \\\n",
    "        Train accuracy:{'%.2f' % (np.sum(currentAccTrain)/len(currentAccTrain))} Valid accuracy:{'%.2f' % (np.sum(currentAcc)/len(currentAcc))} \\\n",
    "        \",end=\"\\x1b\\r\")\n",
    "    accs.append(float(np.sum(currentAcc)/len(currentAcc)))\n",
    "    losses.append(float(np.sum(avgLoss)/len(avgLoss)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now we are doing the RNN stuff \n",
    "Torch RNN\n",
    "\n",
    "\n",
    "<em>Parameters</em>:\n",
    "  <ul>\n",
    "    <li> <p>input_size – The number of expected features in the input x </li>\n",
    "    <li> <p>hidden_size – The number of features in the hidden state h </li>\n",
    "    <li> <p>num_layers – Number of recurrent layers. \n",
    "    <br>E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1 </li>\n",
    "    <li> <p>nonlinearity – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh' </li>\n",
    "    <li> <p>bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True </li>\n",
    "    <li> <p>batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: False \n",
    "    <li> <p>dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0 </li>\n",
    "    <li> <p>bidirectional – If True, becomes a bidirectional RNN. Default: False </li>\n",
    "  </ul>\n",
    "\n",
    "$ h_t = \\tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh}) $\n",
    "\n",
    "where:\n",
    "<ul>\n",
    "<li> N =batch size </li>\n",
    "<li> L = sequence length </li>\n",
    "<li> D = 2 if bidirectional=True otherwise 1 </li>\n",
    "<li> $H_{in}$ = input_size </li>\n",
    "<li> $H_{out}$ = hidden_size </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of experments: 888\n",
      "Number of time steps: 10\n",
      "Number of frames per time step: 1200\n",
      "One fame: 0\n",
      "Total inputs: 888, targets: 888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([144]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folder = set above when we orginal read in the data\n",
    "oneTimeUnitInFPS = oneMinInFPS\n",
    "totalRuntime = 10*oneMinInFPS\n",
    "targets = [i[1] for i in data]\n",
    "timeSlices = []\n",
    "for startTime in range(0, totalRuntime, oneTimeUnitInFPS):\n",
    "    data = expermentDataloader(\n",
    "        f\"{folder}/index.csv\",\n",
    "        f\"{folder}\", \n",
    "        length = oneTimeUnitInFPS,\n",
    "        start=startTime\n",
    "    )\n",
    "    timeSlices.append([np.array(i[0]) for i in data])\n",
    "rawInput = list(zip(*timeSlices))\n",
    "rawInput = [np.array(i) for i in rawInput]\n",
    "print(f\"Number of experments: {len(rawInput)}\")\n",
    "print(f\"Number of time steps: {len(rawInput[0])}\")\n",
    "print(f\"Number of frames per time step: {len(rawInput[0][0])}\")\n",
    "print(f\"One fame: {rawInput[0][0][0]}\")\n",
    "print(f\"Total inputs: {len(rawInput)}, targets: {len(targets)}\")\n",
    "rawData = list(zip(rawInput,targets))\n",
    "rawData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rawData[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 200\n",
      "Valid dataset size: 100\n",
      "Testing dataset size: 588\n",
      "Total: 888\n",
      "number train batches:20\n",
      "number valid batches:10\n",
      "number test batches:1\n"
     ]
    }
   ],
   "source": [
    "trainValidData = []\n",
    "testData = []\n",
    "addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "\n",
    "np.random.shuffle(trainValidData)\n",
    "trainData = []\n",
    "validData = []\n",
    "addData(trainData, validData, trainValidData, rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "trainDataset = DataLoader(trainData, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) \n",
    "validDataset = DataLoader(validData, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "testDataset = DataLoader(testData, batch_size=len(testData), shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "print(f\"Training dataset size: {len(trainData)}\")\n",
    "print(f\"Valid dataset size: {len(validData)}\")\n",
    "print(f\"Testing dataset size: {len(testData)}\")\n",
    "print(f\"Total: {len(trainData) + len(validData) + len(testData)}\")\n",
    "print(f\"number train batches:{len(trainDataset)}\")\n",
    "print(f\"number valid batches:{len(validDataset)}\")\n",
    "print(f\"number test batches:{len(testDataset)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Inputs:</em> input, h_0\n",
    "\n",
    "<em>input</em>: tensor of shape $ L, H_{in} $ for unbatched input, or batched input as $ (L, N, H_{in}) $ <br>\n",
    "when <em>batch_first=False</em> or $(N, L, H_{in})$ when <em>batch_first=True</em>. <br>\n",
    "The input can also be a packed variable length sequence. <br>\n",
    "See <em>torch.nn.utils.rnn.pack_padded_sequence</em> or <br>\n",
    "<em>torch.nn.utils.rnn.pack_sequence</em> for details.\n",
    "\n",
    "<em>h_0</em>: tensor of shape $(D * \\text{num\\_layers}, H_{out})$ for unbatched input or <br>\n",
    "$(D * \\text{num\\_layers}, N, H_{out})$ for batched containing the initial hidden <br>\n",
    "state for the input sequence batch. <br>\n",
    "<b>Defaults to zeros if not provided</b>.\n",
    "\n",
    "where:\n",
    "<ul>\n",
    "<li> N =batch size </li>\n",
    "<li> L = sequence length </li>\n",
    "<li> D = 2 if bidirectional=True otherwise 1 </li>\n",
    "<li> $H_{in}$ = input_size </li>\n",
    "<li> $H_{out}$ = hidden_size </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, featIn, capacity):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.capacity = capacity\n",
    "        self.featIn = featIn\n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(featIn, self.capacity, 2, batch_first=True, nonlinearity='tanh', dropout=0.2)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(capacity, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(2, x.size(0),self.capacity).to(device)\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RNNModel(\\n  (rnn): RNN(1200, 720, num_layers=2, batch_first=True, dropout=0.2)\\n  (fc): Linear(in_features=720, out_features=1, bias=True)\\n)'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(featIn=oneTimeUnitInFPS, capacity=int(featIn*0.06))\n",
    "model = model.to(device)\n",
    "str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input and hidden tensors are not at the same device, found input tensor at cuda:3 and hidden tensor at cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i, (inputs, targets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainDataset):\n\u001b[1;32m     14\u001b[0m     inputs, targets\u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device), targets\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     16\u001b[0m     loss \u001b[39m=\u001b[39m MSE(outputs, targets)\n\u001b[1;32m     17\u001b[0m     avgLossTrain\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(loss\u001b[39m.\u001b[39mitem()))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[62], line 18\u001b[0m, in \u001b[0;36mRNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m h0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39m2\u001b[39m, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m),\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapacity)\n\u001b[1;32m     17\u001b[0m \u001b[39m# One time step\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m out, hn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(x, h0)\n\u001b[1;32m     19\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]) \n\u001b[1;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/modules/rnn.py:522\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    521\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRNN_TANH\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 522\u001b[0m         result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mrnn_tanh(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    523\u001b[0m                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional,\n\u001b[1;32m    524\u001b[0m                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    525\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m         result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mrnn_relu(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    527\u001b[0m                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional,\n\u001b[1;32m    528\u001b[0m                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and hidden tensors are not at the same device, found input tensor at cuda:3 and hidden tensor at cpu"
     ]
    }
   ],
   "source": [
    "MSE = nn.MSELoss(reduction = 'mean')\n",
    "adam = torch.optim.Adam(model.parameters(),lr=0.0001,weight_decay=1e-5)\n",
    "\n",
    "em = 20\n",
    "epochs = 100\n",
    "losses = []\n",
    "accs = []\n",
    "print(\"training...\")\n",
    "for e in range(epochs): \n",
    "    avgLossTrain = []\n",
    "    currentAccTrain = []\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(trainDataset):\n",
    "        inputs, targets= inputs.float().to(device), targets.float().to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = MSE(outputs, targets)\n",
    "        avgLossTrain.append(float(loss.item()))\n",
    "        adam.zero_grad()\n",
    "        loss.backward()\n",
    "        adam.step()\n",
    "        totalCorrect = torch.sum(torch.isclose(outputs.int(), targets.int(), atol=em))\n",
    "        totalCorrect = totalCorrect.item()\n",
    "        currentAccTrain.append(float(totalCorrect/len(targets)))\n",
    "        \n",
    "    avgLoss = []\n",
    "    currentAcc = []\n",
    "    model.eval()\n",
    "    for i, (inputs, targets) in enumerate(validDataset):\n",
    "        inputs, targets= inputs.float().to(device), targets.float().to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = MSE(outputs, targets)\n",
    "        outputPlot = outputs.clone().detach().cpu().numpy()\n",
    "        targetsPlot = targets.clone().detach().cpu().numpy()\n",
    "        avgLoss.append(float(loss.clone().detach().cpu().numpy()))\n",
    "        totalCorrect = torch.sum(torch.isclose(outputs.int(), targets.int(), atol=em))\n",
    "        totalCorrect = totalCorrect.clone().detach().cpu().numpy()\n",
    "        currentAcc.append(float(totalCorrect/len(targets)))\n",
    "        print(f\"\\\n",
    "        epoch: {e}/{epochs}\\t \\\n",
    "        Train Loss:{'%.4f' % (np.sum(avgLossTrain)/len(avgLossTrain))} Valid Loss:{'%.4f' % (np.sum(avgLoss)/len(avgLoss))}\\t \\\n",
    "        Train accuracy:{'%.2f' % (np.sum(currentAccTrain)/len(currentAccTrain))} Valid accuracy:{'%.2f' % (np.sum(currentAcc)/len(currentAcc))} \\\n",
    "        \",end=\"\\x1b\\r\")\n",
    "    accs.append(float(np.sum(currentAcc)/len(currentAcc)))\n",
    "    losses.append(float(np.sum(avgLoss)/len(avgLoss)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchbenchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
