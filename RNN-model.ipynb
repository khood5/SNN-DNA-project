{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dnaDataloader import expermentDataloader\n",
    "from dnaModelUtil import RNNModel\n",
    "from dnaModelUtil import train\n",
    "from dnaDataloader import addData\n",
    "from dnaDataloader import expermentDataloader\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "oneMinInFPS = 1200\n",
    "batch_size = 10\n",
    "num_workers = 0\n",
    "movieRuntime = 5\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   mp.set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "   pass # throws error if run twice without resetting the kernal, if its already set we dont care that this errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch RNN\n",
    "\n",
    "Looks like torch RNN model handles most of the internal workings of a RNN model. \n",
    "\n",
    "<em>Parameters</em>:\n",
    "  <ul>\n",
    "    <li> <p>input_size – The number of expected features in the input x </li>\n",
    "    <li> <p>hidden_size – The number of features in the hidden state h </li>\n",
    "    <li> <p>num_layers – Number of recurrent layers. \n",
    "    <br>E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1 </li>\n",
    "    <li> <p>nonlinearity – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh' </li>\n",
    "    <li> <p>bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True </li>\n",
    "    <li> <p>batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: False \n",
    "    <li> <p>dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0 </li>\n",
    "    <li> <p>bidirectional – If True, becomes a bidirectional RNN. Default: False </li>\n",
    "  </ul>\n",
    "\n",
    "$ h_t = \\tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh}) $\n",
    "\n",
    "where:\n",
    "\n",
    "<br>N = batch size \n",
    "<br>L = sequence length\n",
    "<br>D = 2 if bidirectional=True otherwise 1 \n",
    "<br>$H_{in}$ = input_size \n",
    "<br>$H_{out}$ = hidden_size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [d[0] for d in os.walk(\"/users/kent/student/khood5/GitHub/SNN-DNA-project/Prepocessing/sorted\")][1:] # remove first one is it is \"/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted\"\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 21\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m startTime \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, totalRuntime, oneMinInFPS):\n\u001b[1;32m     15\u001b[0m     data \u001b[39m=\u001b[39m expermentDataloader(\n\u001b[1;32m     16\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00md\u001b[39m}\u001b[39;00m\u001b[39m/index.csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00md\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     18\u001b[0m         length\u001b[39m=\u001b[39moneTimeUnitInFPS,\n\u001b[1;32m     19\u001b[0m         start\u001b[39m=\u001b[39mstartTime\n\u001b[1;32m     20\u001b[0m     )\n\u001b[0;32m---> 21\u001b[0m     timeSlices\u001b[39m.\u001b[39mappend([np\u001b[39m.\u001b[39marray(i[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data])\n\u001b[1;32m     22\u001b[0m rawInput \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mtimeSlices))\n\u001b[1;32m     23\u001b[0m rawInput \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(rawInput))\n",
      "Cell \u001b[0;32mIn[21], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m startTime \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, totalRuntime, oneMinInFPS):\n\u001b[1;32m     15\u001b[0m     data \u001b[39m=\u001b[39m expermentDataloader(\n\u001b[1;32m     16\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00md\u001b[39m}\u001b[39;00m\u001b[39m/index.csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00md\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     18\u001b[0m         length\u001b[39m=\u001b[39moneTimeUnitInFPS,\n\u001b[1;32m     19\u001b[0m         start\u001b[39m=\u001b[39mstartTime\n\u001b[1;32m     20\u001b[0m     )\n\u001b[0;32m---> 21\u001b[0m     timeSlices\u001b[39m.\u001b[39mappend([np\u001b[39m.\u001b[39marray(i[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data])\n\u001b[1;32m     22\u001b[0m rawInput \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mtimeSlices))\n\u001b[1;32m     23\u001b[0m rawInput \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(rawInput))\n",
      "File \u001b[0;32m~/GitHub/SNN-DNA-project/dnaDataloader.py:25\u001b[0m, in \u001b[0;36mexpermentDataloader.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m---> 25\u001b[0m     expermentMovieFrames \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot_dir,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframes[index]), header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m     26\u001b[0m     expermentMovieFrames \u001b[39m=\u001b[39m expermentMovieFrames[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m     27\u001b[0m     totalNumberOfEvents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[index]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1721\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1718\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1719\u001b[0m         new_rows \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(index)\n\u001b[0;32m-> 1721\u001b[0m     df \u001b[39m=\u001b[39m DataFrame(col_dict, columns\u001b[39m=\u001b[39;49mcolumns, index\u001b[39m=\u001b[39;49mindex)\n\u001b[1;32m   1723\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_currow \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m new_rows\n\u001b[1;32m   1724\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    710\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/core/internals/construction.py:431\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseries\u001b[39;00m \u001b[39mimport\u001b[39;00m Series\n\u001b[0;32m--> 431\u001b[0m     arrays \u001b[39m=\u001b[39m Series(data, index\u001b[39m=\u001b[39;49mcolumns, dtype\u001b[39m=\u001b[39;49m\u001b[39mobject\u001b[39;49m)\n\u001b[1;32m    432\u001b[0m     missing \u001b[39m=\u001b[39m arrays\u001b[39m.\u001b[39misna()\n\u001b[1;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m         \u001b[39m# GH10856\u001b[39;00m\n\u001b[1;32m    435\u001b[0m         \u001b[39m# raise ValueError if only scalars in dict\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/core/series.py:472\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    470\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39m_mgr\n\u001b[1;32m    471\u001b[0m \u001b[39melif\u001b[39;00m is_dict_like(data):\n\u001b[0;32m--> 472\u001b[0m     data, index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_dict(data, index, dtype)\n\u001b[1;32m    473\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/core/series.py:569\u001b[0m, in \u001b[0;36mSeries._init_dict\u001b[0;34m(self, data, index, dtype)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39m# Now we just make sure the order is respected, if any\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mand\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 569\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39;49mreindex(index, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    570\u001b[0m \u001b[39mreturn\u001b[39;00m s\u001b[39m.\u001b[39m_mgr, s\u001b[39m.\u001b[39mindex\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/core/series.py:4918\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[0;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   4901\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m   4902\u001b[0m     NDFrame\u001b[39m.\u001b[39mreindex,  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m   4903\u001b[0m     klass\u001b[39m=\u001b[39m_shared_doc_kwargs[\u001b[39m\"\u001b[39m\u001b[39mklass\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4916\u001b[0m     tolerance\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4917\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m-> 4918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreindex(\n\u001b[1;32m   4919\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   4920\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   4921\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   4922\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   4923\u001b[0m         fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m   4924\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit,\n\u001b[1;32m   4925\u001b[0m         tolerance\u001b[39m=\u001b[39;49mtolerance,\n\u001b[1;32m   4926\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/core/generic.py:5348\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5346\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m   5347\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 5348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39;49m(\n\u001b[1;32m   5349\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_axis(axis_name)\u001b[39m.\u001b[39;49midentical(ax)\n\u001b[1;32m   5350\u001b[0m     \u001b[39mfor\u001b[39;49;00m axis_name, ax \u001b[39min\u001b[39;49;00m axes\u001b[39m.\u001b[39;49mitems()\n\u001b[1;32m   5351\u001b[0m     \u001b[39mif\u001b[39;49;00m ax \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   5352\u001b[0m ):\n\u001b[1;32m   5353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m   5355\u001b[0m \u001b[39m# check if we are a multi reindex\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/core/generic.py:5349\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5346\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m   5347\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   5348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m-> 5349\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_axis(axis_name)\u001b[39m.\u001b[39;49midentical(ax)\n\u001b[1;32m   5350\u001b[0m     \u001b[39mfor\u001b[39;00m axis_name, ax \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   5351\u001b[0m     \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   5352\u001b[0m ):\n\u001b[1;32m   5353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m   5355\u001b[0m \u001b[39m# check if we are a multi reindex\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/core/indexes/base.py:5413\u001b[0m, in \u001b[0;36mIndex.identical\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   5401\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   5402\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39midentical\u001b[39m(\u001b[39mself\u001b[39m, other) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   5403\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5404\u001b[0m \u001b[39m    Similar to equals, but checks that object attributes and types are also equal.\u001b[39;00m\n\u001b[1;32m   5405\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5410\u001b[0m \u001b[39m        otherwise False.\u001b[39;00m\n\u001b[1;32m   5411\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   5412\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m-> 5413\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mequals(other)\n\u001b[1;32m   5414\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m   5415\u001b[0m             \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, c, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mgetattr\u001b[39m(other, c, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   5416\u001b[0m             \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_comparables\n\u001b[1;32m   5417\u001b[0m         )\n\u001b[1;32m   5418\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mtype\u001b[39m(other)\n\u001b[1;32m   5419\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m other\u001b[39m.\u001b[39mdtype\n\u001b[1;32m   5420\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/core/indexes/base.py:5399\u001b[0m, in \u001b[0;36mIndex.equals\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   5395\u001b[0m \u001b[39mif\u001b[39;00m is_extension_array_dtype(other\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m   5396\u001b[0m     \u001b[39m# All EA-backed Index subclasses override equals\u001b[39;00m\n\u001b[1;32m   5397\u001b[0m     \u001b[39mreturn\u001b[39;00m other\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> 5399\u001b[0m \u001b[39mreturn\u001b[39;00m array_equivalent(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, other\u001b[39m.\u001b[39;49m_values)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/core/dtypes/missing.py:542\u001b[0m, in \u001b[0;36marray_equivalent\u001b[0;34m(left, right, strict_nan, dtype_equal)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    538\u001b[0m     left\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mvoid \u001b[39mor\u001b[39;00m right\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mvoid\n\u001b[1;32m    539\u001b[0m ) \u001b[39mand\u001b[39;00m left\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m right\u001b[39m.\u001b[39mdtype:\n\u001b[1;32m    540\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49marray_equal(left, right)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/numpy/core/numeric.py:2439\u001b[0m, in \u001b[0;36marray_equal\u001b[0;34m(a1, a2, equal_nan)\u001b[0m\n\u001b[1;32m   2437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m equal_nan:\n\u001b[0;32m-> 2439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(asarray(a1 \u001b[39m==\u001b[39;49m a2)\u001b[39m.\u001b[39mall())\n\u001b[1;32m   2440\u001b[0m \u001b[39m# Handling NaN values if equal_nan is True\u001b[39;00m\n\u001b[1;32m   2441\u001b[0m a1nan, a2nan \u001b[39m=\u001b[39m isnan(a1), isnan(a2)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "featIn = 0\n",
    "totalRuntime = 10*oneMinInFPS\n",
    "oneTimeUnitInFPS = oneMinInFPS\n",
    "for d in folders:\n",
    "    data = expermentDataloader(\n",
    "        f\"{d}/index.csv\",\n",
    "        f\"{d}\", \n",
    "        length=10*oneMinInFPS,\n",
    "    )\n",
    "    targets = [i[1] for i in data]\n",
    "    timeSlices = []\n",
    "    for startTime in range(0, totalRuntime, oneMinInFPS):\n",
    "    \n",
    "        data = expermentDataloader(\n",
    "            f\"{d}/index.csv\",\n",
    "            f\"{d}\", \n",
    "            length=oneTimeUnitInFPS,\n",
    "            start=startTime\n",
    "        )\n",
    "        timeSlices.append([np.array(i[0]) for i in data])\n",
    "    rawInput = list(zip(*timeSlices))\n",
    "    rawInput = np.array(list(rawInput))\n",
    "    rawData = list(zip(rawInput, targets))\n",
    "    rawData = [list(i) for i in rawData]\n",
    "\n",
    "    trainValidData = []\n",
    "    testData = []\n",
    "    addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "\n",
    "    np.random.shuffle(trainValidData)\n",
    "    trainData = []\n",
    "    validData = []\n",
    "    addData(trainData, validData, trainValidData, rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "    datasets.append({\"name\": f\"{os.path.basename(d)}_RNN\", \n",
    "                     \"train\":DataLoader(trainData, batch_size=batch_size, shuffle=True) , \n",
    "                     \"valid\":DataLoader(validData, batch_size=batch_size, shuffle=True) , \n",
    "                     \"test\":DataLoader(testData, batch_size=len(testData), shuffle=True) ,\n",
    "                     \"model\": {}}\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneTimeUnitInFPS = 200\n",
    "# totalRuntime = 10*oneMinInFPS\n",
    "# folder = '/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted/1800_nM_AR_5000'\n",
    "\n",
    "# data = expermentDataloader(\n",
    "#     f\"{folder}/index.csv\",\n",
    "#     f\"{folder}\",\n",
    "    \n",
    "# )\n",
    "# targets = [i[1] for i in data]\n",
    "# timeSlices = []\n",
    "# for startTime in range(oneTimeUnitInFPS, totalRuntime+1, oneTimeUnitInFPS):\n",
    "#     data = expermentDataloader(\n",
    "#         f\"{folder}/index.csv\",\n",
    "#         f\"{folder}\",\n",
    "#         length=oneTimeUnitInFPS,\n",
    "#         start=startTime\n",
    "#     )\n",
    "#     timeSlices.append([np.array(i[0]) for i in data])\n",
    "# rawInput = list(zip(*timeSlices))\n",
    "# rawInput = [np.array(i) for i in rawInput]\n",
    "# print(f\"Number of experments: {len(rawInput)}\")\n",
    "# print(f\"Number of time steps: {len(rawInput[0])}\")\n",
    "# print(f\"Number of frames per time step: {len(rawInput[0][0])}\")\n",
    "# print(f\"One fame: {rawInput[0][0][0]}\")\n",
    "# print(f\"Total inputs: {len(rawInput)}, targets: {len(targets)}\")\n",
    "# rawData = list(zip(rawInput, targets))\n",
    "# rawData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rawData[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featIn = oneMinInFPS if len(rawData[0][0][0]) == oneMinInFPS else None\n",
    "featIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainValidData = []\n",
    "# testData = []\n",
    "# addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "\n",
    "# np.random.shuffle(trainValidData)\n",
    "# trainData = []\n",
    "# validData = []\n",
    "# addData(trainData, validData, trainValidData,\n",
    "#         rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "# trainDataset = DataLoader(trainData, batch_size=batch_size,\n",
    "#                           shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "# validDataset = DataLoader(validData, batch_size=batch_size,\n",
    "#                           shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "# testDataset = DataLoader(testData, batch_size=len(\n",
    "#     testData), shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "# print(f\"Training dataset size: {len(trainData)}\")\n",
    "# print(f\"Valid dataset size: {len(validData)}\")\n",
    "# print(f\"Testing dataset size: {len(testData)}\")\n",
    "# print(f\"Total: {len(trainData) + len(validData) + len(testData)}\")\n",
    "# print(f\"number train batches:{len(trainDataset)}\")\n",
    "# print(f\"number valid batches:{len(validDataset)}\")\n",
    "# print(f\"number test batches:{len(testDataset)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Inputs:</em> input, h_0\n",
    "\n",
    "<em>input</em>: tensor of shape $ L, H_{in} $ for unbatched input, or batched input as $ (L, N, H_{in}) $ <br>\n",
    "when <em>batch_first=False</em> or $(N, L, H_{in})$ when <em>batch_first=True</em>. <br>\n",
    "The input can also be a packed variable length sequence. <br>\n",
    "See <em>torch.nn.utils.rnn.pack_padded_sequence</em> or <br>\n",
    "<em>torch.nn.utils.rnn.pack_sequence</em> for details.\n",
    "\n",
    "<em>h_0</em>: tensor of shape $(D * \\text{num\\_layers}, H_{out})$ for unbatched input or <br>\n",
    "$(D * \\text{num\\_layers}, N, H_{out})$ for batched containing the initial hidden <br>\n",
    "state for the input sequence batch. <br>\n",
    "<b>Defaults to zeros if not provided</b>.\n",
    "\n",
    "where:\n",
    "<br> N = batch size \n",
    "<br> L = sequence length \n",
    "<br> D = 2 if bidirectional=True otherwise 1 \n",
    "<br> $H_{in}$ = input_size \n",
    "<br> $H_{out}$ = hidden_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = mp.Manager()\n",
    "return_dict = manager.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Process name='Process-2' parent=664960 initial>,\n",
       " <Process name='Process-3' parent=664960 initial>,\n",
       " <Process name='Process-4' parent=664960 initial>,\n",
       " <Process name='Process-5' parent=664960 initial>,\n",
       " <Process name='Process-6' parent=664960 initial>,\n",
       " <Process name='Process-7' parent=664960 initial>,\n",
       " <Process name='Process-8' parent=664960 initial>,\n",
       " <Process name='Process-9' parent=664960 initial>,\n",
       " <Process name='Process-10' parent=664960 initial>,\n",
       " <Process name='Process-11' parent=664960 initial>,\n",
       " <Process name='Process-12' parent=664960 initial>,\n",
       " <Process name='Process-13' parent=664960 initial>,\n",
       " <Process name='Process-14' parent=664960 initial>,\n",
       " <Process name='Process-15' parent=664960 initial>,\n",
       " <Process name='Process-16' parent=664960 initial>,\n",
       " <Process name='Process-17' parent=664960 initial>,\n",
       " <Process name='Process-18' parent=664960 initial>,\n",
       " <Process name='Process-19' parent=664960 initial>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processes = []\n",
    "devices = [torch.device(\"cuda:0\")]\n",
    "epochs = 3\n",
    "for error_margin in range(10,13):\n",
    "    for d in datasets:\n",
    "        model = RNNModel(featIn=featIn, capacity=int(700),\n",
    "                 hiddenLayers=2)\n",
    "        MSE = nn.MSELoss(reduction='sum')\n",
    "        adam = torch.optim.Adam(model.parameters(),lr=0.000001,weight_decay=1e-5)\n",
    "        processes.append(mp.Process(target=train, args=(d[\"train\"], d[\"valid\"], f\"{d['name']}_{error_margin}\", \"./Models/smallTrainRNN/\", model, MSE, return_dict, epochs, return_dict, error_margin, devices[0])))\n",
    "        devices.append(devices.pop(0))\n",
    "    \n",
    "processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n",
      "Process Process-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/kent/student/khood5/anaconda3/envs/torch-gpu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/kent/student/khood5/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 32, in train\n",
      "    optim.zero_grad()\n",
      "AttributeError: 'DictProxy' object has no attribute 'zero_grad'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "number_og_GPUs = len(devices)\n",
    "processesList = list(range(len(processes)))\n",
    "while processesList:\n",
    "    run = processesList[:number_og_GPUs]\n",
    "    processesList = processesList[number_og_GPUs:]\n",
    "    for i in run:\n",
    "        processes[i].start()\n",
    "    for i in run:\n",
    "        processes[i].join()\n",
    "        processes[i].terminate()\n",
    "print(return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNNModel(featIn=oneTimeUnitInFPS, capacity=int(400),\n",
    "#                  hiddenLayers=4).to(device)\n",
    "# MSE = nn.MSELoss(reduction='mean')\n",
    "# adam = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "# epochs = 1000\n",
    "# em = 20\n",
    "# trainDataset\n",
    "# validDataset\n",
    "# losses = []\n",
    "# accs = []\n",
    "# losses_t = []\n",
    "# accs_t = []\n",
    "# print(\"training...\")\n",
    "# for e in range(epochs):\n",
    "#     avgLossTrain = []\n",
    "#     currentAccTrain = []\n",
    "#     model.train()\n",
    "#     for i, (inputs, targets) in enumerate(trainDataset):\n",
    "#         inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         loss = MSE(outputs, targets)\n",
    "#         avgLossTrain.append(float(loss.item()))\n",
    "#         adam.zero_grad()\n",
    "#         loss.backward()\n",
    "#         adam.step()\n",
    "#         totalCorrect = torch.sum(torch.isclose(\n",
    "#             outputs.int(), targets.int(), atol=em))\n",
    "#         totalCorrect = totalCorrect.item()\n",
    "#         currentAccTrain.append(float(totalCorrect/len(targets)))\n",
    "#     accs_t.append(float(np.sum(currentAccTrain)/len(currentAccTrain)))\n",
    "#     losses_t.append(float(np.sum(avgLossTrain)/len(avgLossTrain)))\n",
    "\n",
    "#     avgLoss = []\n",
    "#     currentAcc = []\n",
    "#     model.eval()\n",
    "#     for i, (inputs, targets) in enumerate(validDataset):\n",
    "#         inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         loss = MSE(outputs, targets)\n",
    "#         outputPlot = outputs.clone().detach().cpu().numpy()\n",
    "#         targetsPlot = targets.clone().detach().cpu().numpy()\n",
    "#         avgLoss.append(float(loss.clone().detach().cpu().numpy()))\n",
    "#         totalCorrect = torch.sum(torch.isclose(\n",
    "#             outputs.int(), targets.int(), atol=em))\n",
    "#         totalCorrect = totalCorrect.clone().detach().cpu().numpy()\n",
    "#         currentAcc.append(float(totalCorrect/len(targets)))\n",
    "#         print(f\"\\\n",
    "#         epoch: {e}/{epochs}\\t \\\n",
    "#         Train Loss:{'%.4f' % (np.sum(avgLossTrain)/len(avgLossTrain))} Valid Loss:{'%.4f' % (np.sum(avgLoss)/len(avgLoss))}\\t \\\n",
    "#         Train accuracy:{'%.2f' % (np.sum(currentAccTrain)/len(currentAccTrain))} Valid accuracy:{'%.2f' % (np.sum(currentAcc)/len(currentAcc))} \\\n",
    "#         \", end=\"\\x1b\\r\")\n",
    "#     accs.append(float(np.sum(currentAcc)/len(currentAcc)))\n",
    "#     losses.append(float(np.sum(avgLoss)/len(avgLoss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defultePlotSize = plt.rcParams['figure.figsize']\n",
    "# plt.rcParams['figure.figsize'] = [40, 20]\n",
    "\n",
    "# plt.subplot(2, 2, 1)\n",
    "# plt.title(f'accuracy vs epochs training {totalRuntime/oneMinInFPS} min')\n",
    "# plt.plot(list(range(len(accs_t[:]))), accs_t[:], '-', color='black', )\n",
    "# plt.subplot(2, 2, 2)\n",
    "# plt.title(f'losse vs epochs training {totalRuntime/oneMinInFPS} min')\n",
    "# plt.plot(list(range(len(losses_t)))[:], losses_t[:], '-', color='black')\n",
    "\n",
    "# plt.subplot(2, 2, 3)\n",
    "# plt.title(f'accuracy vs epochs validation {totalRuntime/oneMinInFPS} min')\n",
    "# plt.plot(list(range(len(accs[:]))), accs[:], '-', color='black', )\n",
    "# plt.subplot(2, 2, 4)\n",
    "# plt.title(f'losse vs epochs validation {totalRuntime/oneMinInFPS} min')\n",
    "# plt.plot(list(range(len(losses)))[:], losses[:], '-', color='black')\n",
    "# plt.rcParams['figure.figsize'] = defultePlotSize\n",
    "# print(f\"Best acc: {max(accs)}\")\n",
    "\n",
    "# epochs*len(validDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_valid_acc = None\n",
    "# with open('/home/khood/GitHub/SNN-DNA-project/Models/variedMovie/rnn_valid_acc.json') as f:\n",
    "#     rnn_valid_acc = json.load(f)\n",
    "#     rnn_valid_acc = {k: rnn_valid_acc[k]['acc'] for k in rnn_valid_acc}\n",
    "# sorted_value_rnn_valid_acc = {k: v for k, v in sorted(\n",
    "#     rnn_valid_acc.items(), key=lambda item: item[1])}\n",
    "# sorted_value_rnn_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = list(sorted_value_rnn_valid_acc.keys())\n",
    "# values = list(sorted_value_rnn_valid_acc.values())\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = [20, 5]\n",
    "# plt.bar(range(len(sorted_value_rnn_valid_acc)), values, tick_label=names)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_valid_acc = None\n",
    "# with open('/home/khood/GitHub/SNN-DNA-project/Models/variedMovie/rnn_valid_acc.json') as f:\n",
    "#     rnn_valid_acc = json.load(f)\n",
    "# # make names just length so that it can be sorted\n",
    "# rnn_valid_acc = {int(k.split('_')[1]): rnn_valid_acc[k] for k in rnn_valid_acc}\n",
    "# rnn_valid_acc\n",
    "\n",
    "# myKeys = list(rnn_valid_acc.keys())\n",
    "# myKeys.sort()\n",
    "# sorted_time_rnn_valid_acc = {i: rnn_valid_acc[i] for i in myKeys}\n",
    "# names = list(sorted_time_rnn_valid_acc.keys())\n",
    "# values = list(sorted_time_rnn_valid_acc.values())\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = [20, 5]\n",
    "# plt.bar(range(len(sorted_time_rnn_valid_acc)), values, tick_label=names)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchbenchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
