{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.linalg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/site-packages/matplotlib/__init__.py:129\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m parse \u001b[39mas\u001b[39;00m parse_version\n\u001b[1;32m    127\u001b[0m \u001b[39m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[1;32m    130\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcbook\u001b[39;00m \u001b[39mimport\u001b[39;00m sanitize_sequence\n\u001b[1;32m    131\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m \u001b[39mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/site-packages/matplotlib/rcsetup.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, cbook\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcbook\u001b[39;00m \u001b[39mimport\u001b[39;00m ls_mapper\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolors\u001b[39;00m \u001b[39mimport\u001b[39;00m Colormap, is_color_like\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_fontconfig_pattern\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_enums\u001b[39;00m \u001b[39mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/site-packages/matplotlib/colors.py:56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[1;32m     57\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_color_data\u001b[39;00m \u001b[39mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[1;32m     60\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_ColorMapping\u001b[39;00m(\u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/site-packages/matplotlib/scale.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, _docstring\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mticker\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[1;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[1;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[1;32m     29\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mScaleBase\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/site-packages/matplotlib/ticker.py:138\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, cbook\n\u001b[0;32m--> 138\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms \u001b[39mas\u001b[39;00m mtransforms\n\u001b[1;32m    140\u001b[0m _log \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    142\u001b[0m __all__ \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mTickHelper\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFormatter\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFixedFormatter\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    143\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mNullFormatter\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFuncFormatter\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFormatStrFormatter\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    144\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mStrMethodFormatter\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mScalarFormatter\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLogFormatter\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mMultipleLocator\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMaxNLocator\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAutoMinorLocator\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    151\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mSymmetricalLogLocator\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAsinhLocator\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLogitLocator\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/site-packages/matplotlib/transforms.py:46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m \u001b[39mimport\u001b[39;00m inv\n\u001b[1;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _api\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_path\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.linalg'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.multiprocessing as mp\n",
    "from dnaDataloader import expermentDataloader\n",
    "from dnaModelUtil import RNNModel\n",
    "from dnaModelUtil import train\n",
    "from dnaDataloader import addData\n",
    "from dnaDataloader import expermentDataloader\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "oneMinInFPS = 1200\n",
    "batch_size = 10\n",
    "num_workers = 0\n",
    "movieRuntime = 5\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   mp.set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "   pass # throws error if run twice without resetting the kernal, if its already set we dont care that this errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch RNN\n",
    "\n",
    "Looks like torch RNN model handles most of the internal workings of a RNN model. \n",
    "\n",
    "<em>Parameters</em>:\n",
    "  <ul>\n",
    "    <li> <p>input_size – The number of expected features in the input x </li>\n",
    "    <li> <p>hidden_size – The number of features in the hidden state h </li>\n",
    "    <li> <p>num_layers – Number of recurrent layers. \n",
    "    <br>E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1 </li>\n",
    "    <li> <p>nonlinearity – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh' </li>\n",
    "    <li> <p>bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True </li>\n",
    "    <li> <p>batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: False \n",
    "    <li> <p>dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0 </li>\n",
    "    <li> <p>bidirectional – If True, becomes a bidirectional RNN. Default: False </li>\n",
    "  </ul>\n",
    "\n",
    "$ h_t = \\tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh}) $\n",
    "\n",
    "where:\n",
    "\n",
    "<br>N = batch size \n",
    "<br>L = sequence length\n",
    "<br>D = 2 if bidirectional=True otherwise 1 \n",
    "<br>$H_{in}$ = input_size \n",
    "<br>$H_{out}$ = hidden_size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [d[0] for d in os.walk(\"/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted\")][1:] # remove first one is it is \"/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted\"\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "featIn = 0\n",
    "totalRuntime = 10*oneMinInFPS\n",
    "oneTimeUnitInFPS = oneMinInFPS\n",
    "for d in folders:\n",
    "    data = expermentDataloader(\n",
    "        f\"{d}/index.csv\",\n",
    "        f\"{d}\", \n",
    "        length=10*oneMinInFPS,\n",
    "    )\n",
    "    targets = [i[1] for i in data]\n",
    "    timeSlices = []\n",
    "    for startTime in range(0, totalRuntime, oneMinInFPS):\n",
    "    \n",
    "        data = expermentDataloader(\n",
    "            f\"{d}/index.csv\",\n",
    "            f\"{d}\", \n",
    "            length=oneTimeUnitInFPS,\n",
    "            start=startTime\n",
    "        )\n",
    "        timeSlices.append([np.array(i[0]) for i in data])\n",
    "    rawInput = list(zip(*timeSlices))\n",
    "    rawInput = np.array(list(rawInput))\n",
    "    rawData = list(zip(rawInput, targets))\n",
    "    rawData = [list(i) for i in rawData]\n",
    "\n",
    "    trainValidData = []\n",
    "    testData = []\n",
    "    addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "\n",
    "    np.random.shuffle(trainValidData)\n",
    "    trainData = []\n",
    "    validData = []\n",
    "    addData(trainData, validData, trainValidData, rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "    datasets.append({\"name\": f\"{os.path.basename(d)}_RNN\", \n",
    "                     \"train\":DataLoader(trainData, batch_size=batch_size, shuffle=True) , \n",
    "                     \"valid\":DataLoader(validData, batch_size=batch_size, shuffle=True) , \n",
    "                     \"test\":DataLoader(testData, batch_size=len(testData), shuffle=True) ,\n",
    "                     \"model\": {}}\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneTimeUnitInFPS = 200\n",
    "# totalRuntime = 10*oneMinInFPS\n",
    "# folder = '/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted/1800_nM_AR_5000'\n",
    "\n",
    "# data = expermentDataloader(\n",
    "#     f\"{folder}/index.csv\",\n",
    "#     f\"{folder}\",\n",
    "    \n",
    "# )\n",
    "# targets = [i[1] for i in data]\n",
    "# timeSlices = []\n",
    "# for startTime in range(oneTimeUnitInFPS, totalRuntime+1, oneTimeUnitInFPS):\n",
    "#     data = expermentDataloader(\n",
    "#         f\"{folder}/index.csv\",\n",
    "#         f\"{folder}\",\n",
    "#         length=oneTimeUnitInFPS,\n",
    "#         start=startTime\n",
    "#     )\n",
    "#     timeSlices.append([np.array(i[0]) for i in data])\n",
    "# rawInput = list(zip(*timeSlices))\n",
    "# rawInput = [np.array(i) for i in rawInput]\n",
    "# print(f\"Number of experments: {len(rawInput)}\")\n",
    "# print(f\"Number of time steps: {len(rawInput[0])}\")\n",
    "# print(f\"Number of frames per time step: {len(rawInput[0][0])}\")\n",
    "# print(f\"One fame: {rawInput[0][0][0]}\")\n",
    "# print(f\"Total inputs: {len(rawInput)}, targets: {len(targets)}\")\n",
    "# rawData = list(zip(rawInput, targets))\n",
    "# rawData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rawData[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featIn = oneMinInFPS if len(rawData[0][0][0]) == oneMinInFPS else None\n",
    "featIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainValidData = []\n",
    "# testData = []\n",
    "# addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "\n",
    "# np.random.shuffle(trainValidData)\n",
    "# trainData = []\n",
    "# validData = []\n",
    "# addData(trainData, validData, trainValidData,\n",
    "#         rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "# trainDataset = DataLoader(trainData, batch_size=batch_size,\n",
    "#                           shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "# validDataset = DataLoader(validData, batch_size=batch_size,\n",
    "#                           shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "# testDataset = DataLoader(testData, batch_size=len(\n",
    "#     testData), shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "# print(f\"Training dataset size: {len(trainData)}\")\n",
    "# print(f\"Valid dataset size: {len(validData)}\")\n",
    "# print(f\"Testing dataset size: {len(testData)}\")\n",
    "# print(f\"Total: {len(trainData) + len(validData) + len(testData)}\")\n",
    "# print(f\"number train batches:{len(trainDataset)}\")\n",
    "# print(f\"number valid batches:{len(validDataset)}\")\n",
    "# print(f\"number test batches:{len(testDataset)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Inputs:</em> input, h_0\n",
    "\n",
    "<em>input</em>: tensor of shape $ L, H_{in} $ for unbatched input, or batched input as $ (L, N, H_{in}) $ <br>\n",
    "when <em>batch_first=False</em> or $(N, L, H_{in})$ when <em>batch_first=True</em>. <br>\n",
    "The input can also be a packed variable length sequence. <br>\n",
    "See <em>torch.nn.utils.rnn.pack_padded_sequence</em> or <br>\n",
    "<em>torch.nn.utils.rnn.pack_sequence</em> for details.\n",
    "\n",
    "<em>h_0</em>: tensor of shape $(D * \\text{num\\_layers}, H_{out})$ for unbatched input or <br>\n",
    "$(D * \\text{num\\_layers}, N, H_{out})$ for batched containing the initial hidden <br>\n",
    "state for the input sequence batch. <br>\n",
    "<b>Defaults to zeros if not provided</b>.\n",
    "\n",
    "where:\n",
    "<br> N = batch size \n",
    "<br> L = sequence length \n",
    "<br> D = 2 if bidirectional=True otherwise 1 \n",
    "<br> $H_{in}$ = input_size \n",
    "<br> $H_{out}$ = hidden_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = mp.Manager()\n",
    "return_dict = manager.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Process name='Process-2' parent=24826 initial>,\n",
       " <Process name='Process-3' parent=24826 initial>,\n",
       " <Process name='Process-4' parent=24826 initial>,\n",
       " <Process name='Process-5' parent=24826 initial>,\n",
       " <Process name='Process-6' parent=24826 initial>,\n",
       " <Process name='Process-7' parent=24826 initial>,\n",
       " <Process name='Process-8' parent=24826 initial>,\n",
       " <Process name='Process-9' parent=24826 initial>,\n",
       " <Process name='Process-10' parent=24826 initial>,\n",
       " <Process name='Process-11' parent=24826 initial>,\n",
       " <Process name='Process-12' parent=24826 initial>,\n",
       " <Process name='Process-13' parent=24826 initial>,\n",
       " <Process name='Process-14' parent=24826 initial>,\n",
       " <Process name='Process-15' parent=24826 initial>,\n",
       " <Process name='Process-16' parent=24826 initial>,\n",
       " <Process name='Process-17' parent=24826 initial>,\n",
       " <Process name='Process-18' parent=24826 initial>,\n",
       " <Process name='Process-19' parent=24826 initial>,\n",
       " <Process name='Process-20' parent=24826 initial>,\n",
       " <Process name='Process-21' parent=24826 initial>,\n",
       " <Process name='Process-22' parent=24826 initial>,\n",
       " <Process name='Process-23' parent=24826 initial>,\n",
       " <Process name='Process-24' parent=24826 initial>,\n",
       " <Process name='Process-25' parent=24826 initial>,\n",
       " <Process name='Process-26' parent=24826 initial>,\n",
       " <Process name='Process-27' parent=24826 initial>,\n",
       " <Process name='Process-28' parent=24826 initial>,\n",
       " <Process name='Process-29' parent=24826 initial>,\n",
       " <Process name='Process-30' parent=24826 initial>,\n",
       " <Process name='Process-31' parent=24826 initial>,\n",
       " <Process name='Process-32' parent=24826 initial>,\n",
       " <Process name='Process-33' parent=24826 initial>,\n",
       " <Process name='Process-34' parent=24826 initial>,\n",
       " <Process name='Process-35' parent=24826 initial>,\n",
       " <Process name='Process-36' parent=24826 initial>,\n",
       " <Process name='Process-37' parent=24826 initial>,\n",
       " <Process name='Process-38' parent=24826 initial>,\n",
       " <Process name='Process-39' parent=24826 initial>,\n",
       " <Process name='Process-40' parent=24826 initial>,\n",
       " <Process name='Process-41' parent=24826 initial>,\n",
       " <Process name='Process-42' parent=24826 initial>,\n",
       " <Process name='Process-43' parent=24826 initial>,\n",
       " <Process name='Process-44' parent=24826 initial>,\n",
       " <Process name='Process-45' parent=24826 initial>,\n",
       " <Process name='Process-46' parent=24826 initial>,\n",
       " <Process name='Process-47' parent=24826 initial>,\n",
       " <Process name='Process-48' parent=24826 initial>,\n",
       " <Process name='Process-49' parent=24826 initial>,\n",
       " <Process name='Process-50' parent=24826 initial>,\n",
       " <Process name='Process-51' parent=24826 initial>,\n",
       " <Process name='Process-52' parent=24826 initial>,\n",
       " <Process name='Process-53' parent=24826 initial>,\n",
       " <Process name='Process-54' parent=24826 initial>,\n",
       " <Process name='Process-55' parent=24826 initial>,\n",
       " <Process name='Process-56' parent=24826 initial>,\n",
       " <Process name='Process-57' parent=24826 initial>,\n",
       " <Process name='Process-58' parent=24826 initial>,\n",
       " <Process name='Process-59' parent=24826 initial>,\n",
       " <Process name='Process-60' parent=24826 initial>,\n",
       " <Process name='Process-61' parent=24826 initial>,\n",
       " <Process name='Process-62' parent=24826 initial>,\n",
       " <Process name='Process-63' parent=24826 initial>,\n",
       " <Process name='Process-64' parent=24826 initial>,\n",
       " <Process name='Process-65' parent=24826 initial>,\n",
       " <Process name='Process-66' parent=24826 initial>,\n",
       " <Process name='Process-67' parent=24826 initial>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processes = []\n",
    "devices = [torch.device(\"cuda:0\"), torch.device(\"cuda:1\")]\n",
    "epochs = 3\n",
    "for error_margin in range(10,21):\n",
    "    for d in datasets:\n",
    "        model = RNNModel(featIn=featIn, capacity=int(700),\n",
    "                 hiddenLayers=2)\n",
    "        MSE = nn.MSELoss(reduction='sum')\n",
    "        adam = torch.optim.Adam(model.parameters(),lr=0.000001,weight_decay=1e-5)\n",
    "        processes.append(mp.Process(target=train, args=(d[\"train\"], d[\"valid\"], f\"{d['name']}_{error_margin}\", \"./Models/smallTrainRNN/\", model, MSE, return_dict, epochs, return_dict, error_margin, devices[0])))\n",
    "        devices.append(devices.pop(0))\n",
    "    \n",
    "processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.\n",
      "\tTry to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m processesList \u001b[39m=\u001b[39m processesList[number_og_GPUs:]\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m run:\n\u001b[0;32m----> 7\u001b[0m     processes[i]\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m run:\n\u001b[1;32m      9\u001b[0m     processes[i]\u001b[39m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39;49mwrite(fp\u001b[39m.\u001b[39;49mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "number_og_GPUs = len(devices)\n",
    "processesList = list(range(len(processes)))\n",
    "while processesList:\n",
    "    run = processesList[:number_og_GPUs]\n",
    "    processesList = processesList[number_og_GPUs:]\n",
    "    for i in run:\n",
    "        processes[i].start()\n",
    "    for i in run:\n",
    "        processes[i].join()\n",
    "        processes[i].terminate()\n",
    "print(return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNNModel(featIn=oneTimeUnitInFPS, capacity=int(400),\n",
    "#                  hiddenLayers=4).to(device)\n",
    "# MSE = nn.MSELoss(reduction='mean')\n",
    "# adam = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "# epochs = 1000\n",
    "# em = 20\n",
    "# trainDataset\n",
    "# validDataset\n",
    "# losses = []\n",
    "# accs = []\n",
    "# losses_t = []\n",
    "# accs_t = []\n",
    "# print(\"training...\")\n",
    "# for e in range(epochs):\n",
    "#     avgLossTrain = []\n",
    "#     currentAccTrain = []\n",
    "#     model.train()\n",
    "#     for i, (inputs, targets) in enumerate(trainDataset):\n",
    "#         inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         loss = MSE(outputs, targets)\n",
    "#         avgLossTrain.append(float(loss.item()))\n",
    "#         adam.zero_grad()\n",
    "#         loss.backward()\n",
    "#         adam.step()\n",
    "#         totalCorrect = torch.sum(torch.isclose(\n",
    "#             outputs.int(), targets.int(), atol=em))\n",
    "#         totalCorrect = totalCorrect.item()\n",
    "#         currentAccTrain.append(float(totalCorrect/len(targets)))\n",
    "#     accs_t.append(float(np.sum(currentAccTrain)/len(currentAccTrain)))\n",
    "#     losses_t.append(float(np.sum(avgLossTrain)/len(avgLossTrain)))\n",
    "\n",
    "#     avgLoss = []\n",
    "#     currentAcc = []\n",
    "#     model.eval()\n",
    "#     for i, (inputs, targets) in enumerate(validDataset):\n",
    "#         inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         loss = MSE(outputs, targets)\n",
    "#         outputPlot = outputs.clone().detach().cpu().numpy()\n",
    "#         targetsPlot = targets.clone().detach().cpu().numpy()\n",
    "#         avgLoss.append(float(loss.clone().detach().cpu().numpy()))\n",
    "#         totalCorrect = torch.sum(torch.isclose(\n",
    "#             outputs.int(), targets.int(), atol=em))\n",
    "#         totalCorrect = totalCorrect.clone().detach().cpu().numpy()\n",
    "#         currentAcc.append(float(totalCorrect/len(targets)))\n",
    "#         print(f\"\\\n",
    "#         epoch: {e}/{epochs}\\t \\\n",
    "#         Train Loss:{'%.4f' % (np.sum(avgLossTrain)/len(avgLossTrain))} Valid Loss:{'%.4f' % (np.sum(avgLoss)/len(avgLoss))}\\t \\\n",
    "#         Train accuracy:{'%.2f' % (np.sum(currentAccTrain)/len(currentAccTrain))} Valid accuracy:{'%.2f' % (np.sum(currentAcc)/len(currentAcc))} \\\n",
    "#         \", end=\"\\x1b\\r\")\n",
    "#     accs.append(float(np.sum(currentAcc)/len(currentAcc)))\n",
    "#     losses.append(float(np.sum(avgLoss)/len(avgLoss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defultePlotSize = plt.rcParams['figure.figsize']\n",
    "# plt.rcParams['figure.figsize'] = [40, 20]\n",
    "\n",
    "# plt.subplot(2, 2, 1)\n",
    "# plt.title(f'accuracy vs epochs training {totalRuntime/oneMinInFPS} min')\n",
    "# plt.plot(list(range(len(accs_t[:]))), accs_t[:], '-', color='black', )\n",
    "# plt.subplot(2, 2, 2)\n",
    "# plt.title(f'losse vs epochs training {totalRuntime/oneMinInFPS} min')\n",
    "# plt.plot(list(range(len(losses_t)))[:], losses_t[:], '-', color='black')\n",
    "\n",
    "# plt.subplot(2, 2, 3)\n",
    "# plt.title(f'accuracy vs epochs validation {totalRuntime/oneMinInFPS} min')\n",
    "# plt.plot(list(range(len(accs[:]))), accs[:], '-', color='black', )\n",
    "# plt.subplot(2, 2, 4)\n",
    "# plt.title(f'losse vs epochs validation {totalRuntime/oneMinInFPS} min')\n",
    "# plt.plot(list(range(len(losses)))[:], losses[:], '-', color='black')\n",
    "# plt.rcParams['figure.figsize'] = defultePlotSize\n",
    "# print(f\"Best acc: {max(accs)}\")\n",
    "\n",
    "# epochs*len(validDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_valid_acc = None\n",
    "# with open('/home/khood/GitHub/SNN-DNA-project/Models/variedMovie/rnn_valid_acc.json') as f:\n",
    "#     rnn_valid_acc = json.load(f)\n",
    "#     rnn_valid_acc = {k: rnn_valid_acc[k]['acc'] for k in rnn_valid_acc}\n",
    "# sorted_value_rnn_valid_acc = {k: v for k, v in sorted(\n",
    "#     rnn_valid_acc.items(), key=lambda item: item[1])}\n",
    "# sorted_value_rnn_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = list(sorted_value_rnn_valid_acc.keys())\n",
    "# values = list(sorted_value_rnn_valid_acc.values())\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = [20, 5]\n",
    "# plt.bar(range(len(sorted_value_rnn_valid_acc)), values, tick_label=names)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_valid_acc = None\n",
    "# with open('/home/khood/GitHub/SNN-DNA-project/Models/variedMovie/rnn_valid_acc.json') as f:\n",
    "#     rnn_valid_acc = json.load(f)\n",
    "# # make names just length so that it can be sorted\n",
    "# rnn_valid_acc = {int(k.split('_')[1]): rnn_valid_acc[k] for k in rnn_valid_acc}\n",
    "# rnn_valid_acc\n",
    "\n",
    "# myKeys = list(rnn_valid_acc.keys())\n",
    "# myKeys.sort()\n",
    "# sorted_time_rnn_valid_acc = {i: rnn_valid_acc[i] for i in myKeys}\n",
    "# names = list(sorted_time_rnn_valid_acc.keys())\n",
    "# values = list(sorted_time_rnn_valid_acc.values())\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = [20, 5]\n",
    "# plt.bar(range(len(sorted_time_rnn_valid_acc)), values, tick_label=names)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchbenchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
