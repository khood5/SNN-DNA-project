{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import IPython.display as display\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class expermentDataloader(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        index_file: str, \n",
    "        data_path: str,\n",
    "    ):\n",
    "        self.root_dir = data_path\n",
    "        self.expermentSikeTrainsIndex = pd.read_csv(index_file,header=None) # self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.spikeTrains = [\n",
    "            f\"{os.path.join(self.expermentSikeTrainsIndex.iloc[i, 0])}\" for i in range(len(self.expermentSikeTrainsIndex)) \n",
    "        ]\n",
    "        self.targets = self.expermentSikeTrainsIndex.iloc[:, 1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputCSVlines = pd.read_csv(os.path.join(self.root_dir,self.spikeTrains[index])).to_numpy()\n",
    "        targetCSVLines = self.targets[index]\n",
    "        return inputCSVlines.flatten(), np.array([targetCSVLines])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.expermentSikeTrainsIndex)\n",
    "\n",
    "\n",
    "dataPath = \"/home/khood/GitHub/SNN-DNA-project/Prepocessing/data/allData\"\n",
    "dataPathIndex = \"/home/khood/GitHub/SNN-DNA-project/Prepocessing/data/allData/index.csv\"\n",
    "\n",
    "trainingData = expermentDataloader(dataPathIndex,dataPath)\n",
    "# input = trainingData[0][0]\n",
    "# target = trainingData[0][1]\n",
    "data, target = trainingData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([339])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(data)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8999"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainingData[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8999"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainingData[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f10d016fa00>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(trainingData[0][0]))), trainingData[0][0], 'o', color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([339])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=8999, out_features=8999, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8999, out_features=8999, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=8999, out_features=1, bias=True)\n",
       "  (5): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "          nn.Linear(len(data),len(data)),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(len(data),len(data)),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(len(data),1),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = nn.MSELoss()\n",
    "adam = torch.optim.Adam(model.parameters(),lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targetPlot = torch.from_numpy(target[:,0]).float()\n",
    "targetTorch = torch.tensor(target).float().to(device)\n",
    "inputTorch = torch.from_numpy(data).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.3819e-09, device='cuda:1', grad_fn=<MseLossBackward0>))\r"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    output = model(inputTorch)\n",
    "    loss = MSE(output, targetTorch)\n",
    "    adam.zero_grad()\n",
    "    loss.backward()\n",
    "    adam.step()\n",
    "    outputPlot = output.clone().detach().cpu().numpy()\n",
    "    print(loss,end=\"\\r\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([339.0001], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 10\n",
    "dataPath = \"/home/khood/GitHub/SNN-DNA-project/Prepocessing/data/allData\"\n",
    "dataPathIndex = \"/home/khood/GitHub/SNN-DNA-project/Prepocessing/data/allData/index.csv\"\n",
    "trainingData = expermentDataloader(dataPathIndex,dataPath)\n",
    "dataset = DataLoader(trainingData, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m targets\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m      6\u001b[0m loss \u001b[39m=\u001b[39m MSE(outputs, targets)\n\u001b[1;32m      7\u001b[0m adam\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/dna/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataset):\n",
    "    inputs, targets = data\n",
    "    inputs.to(device)\n",
    "    targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = MSE(outputs, targets)\n",
    "    adam.zero_grad()\n",
    "    loss.backward()\n",
    "    adam.step()\n",
    "    outputPlot = outputs.clone().detach().cpu().numpy()\n",
    "    print(loss,end=\"\\r\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
