{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source https://lava-nc.org\n",
    "\n",
    "Working with data from <code>Prepocessing/data/spikeTrains</code> should have folder for each experment setup (in terms of disctance of magnent in mm). Each folder should have a list of spike trains as csv files. Spike trains are recorded as events per 0.05 secs. The index file has the list of each spike train path and the class they are in. Classes are configureable via the preprocessing but should be somthing like this \n",
    "\n",
    "<table style=\"border:none;padding: 10px;margin: auto;\">\n",
    "    <tr style=\"border:none;padding: 10px;margin: auto;\">\n",
    "        <td style=\"border:none;padding: 10px;margin: auto;\">\n",
    "        9/5mm\n",
    "        <table>\n",
    "            <tr> <td>High</td> <td>>300</td> </tr>\n",
    "            <tr> <td>Medium</td> <td>300-230</td> </tr>\n",
    "            <tr> <td>Low</td> <td>&lt;230</td> </tr>\n",
    "        </table>\n",
    "        </td>\n",
    "        <td style=\"border:none;padding: 10px;margin: auto;\">\n",
    "        3mm\n",
    "        <table>\n",
    "            <tr> <td>High</td> <td>>150</td> </tr>\n",
    "            <tr> <td>Medium</td> <td>100-150</td> </tr>\n",
    "            <tr> <td>Low</td> <td>&lt;100</td> </tr>\n",
    "        </table>\n",
    "        </td>\n",
    "        <td style=\"border:none;padding: 10px;margin: auto;\">\n",
    "        2/1.5mm\n",
    "        <table>\n",
    "            <tr> <td>High</td> <td>>50</td> </tr>\n",
    "            <tr> <td>Medium</td> <td>30-50</td> </tr>\n",
    "            <tr> <td>Low</td> <td>&lt;30</td> </tr>\n",
    "        </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "The plan is to use intel lava-nc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our data loader. Should get an index file for an experment type (9mm,5mm etc). The index file should contain a path to each indiviual training experiment and the class it belongs to high, medium, or low.\n",
    "Note that the class is represented as a int, the map is shown below\n",
    "\n",
    "|class         | numerical value|\n",
    "|--------------|----------------|\n",
    "|<i>high</i>   |               2|\n",
    "|<i>medium</i> |               1|\n",
    "|<i>low</i>    |               0|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example index file (Prepocessing/data/spikeTrains/1.5-SpikeTrains/index.csv)\n",
    "<pre>\n",
    "spikeTrain_1.csv,0\n",
    "spikeTrain_2.csv,0\n",
    "spikeTrain_3.csv,1\n",
    "spikeTrain_4.csv,0\n",
    "spikeTrain_5.csv,2\n",
    "spikeTrain_6.csv,1\n",
    "</pre>\n",
    "\n",
    "\n",
    "Example spik train file (Prepocessing/data/spikeTrains/1.5-SpikeTrains/spikeTrain_1.csv)\n",
    "<pre>\n",
    "0\n",
    "0\n",
    "0\n",
    ".\n",
    ".\n",
    ".\n",
    "0\n",
    "0\n",
    "1\n",
    "0\n",
    ".\n",
    ".\n",
    ".\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class expermentDataloader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        index_file: str, \n",
    "        data_path: str,\n",
    "    ):\n",
    "        self.root_dir = data_path\n",
    "        self.expermentSikeTrainsIndex = pd.read_csv(index_file) # self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.spikeTrains = [\n",
    "            f\"{os.path.join(self.expermentSikeTrainsIndex.iloc[i, 0])}\" for i in range(len(self.expermentSikeTrainsIndex)) \n",
    "        ]\n",
    "        self.expermentClasses = self.expermentSikeTrainsIndex.iloc[:, 1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        CSVlines = pd.read_csv(os.path.join(self.root_dir,self.spikeTrains[index])).to_numpy()\n",
    "        eventClass = self.expermentClasses[index]\n",
    "        return np.array(list(CSVlines.flatten())), int(eventClass)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.expermentSikeTrainsIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is NOT all zeros: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 0, 0, 0]), 0)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexFile5mm = \"./Prepocessing/data/spikeTrains/5-SpikeTrains/index.csv\"\n",
    "PathTo5mmSpikeTrains = \"./Prepocessing/data/spikeTrains/5-SpikeTrains\"\n",
    "\n",
    "trainingData = expermentDataloader(indexFile5mm,PathTo5mmSpikeTrains)\n",
    "\n",
    "print(f\"Is NOT all zeros: {np.any(trainingData[0][0])}\")\n",
    "trainingData[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Spike Input Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input processes should read spike trains from the data loader and just feed them into lava-nc models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Processes and Process level primitives\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import  OutPort\n",
    "\n",
    "# Import ProcessModels and ProcessModels level primitives\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "from lava.magma.core.model.py.ports import PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "\n",
    "# Import execution protocol and hardware resources\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.resources import CPU\n",
    "\n",
    "# Import decorators\n",
    "from lava.magma.core.decorator import implements, requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as ty\n",
    "\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "\n",
    "class SpikeInput(AbstractProcess):\n",
    "    def __init__(self,\n",
    "                 vth: int,\n",
    "                 num_spike_trains: ty.Optional[int], # no defulte depends on input experment setting (i.e. 5mm, 3mm etc)\n",
    "                 spike_train_length: ty.Optional[int] = 3000 # Number of steps recorded every 0.05 secs\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        shape = (784,)\n",
    "        self.spikes_out = OutPort(shape=shape)  # Input spikes to the classifier\n",
    "        self.label_out = OutPort(shape=(1,))  # Ground truth labels to OutputProc\n",
    "        self.num_spike_trains = Var(shape=(1,), init=num_spike_trains)\n",
    "        self.spike_train_length = Var(shape=(1,), init=spike_train_length)\n",
    "        self.input_spike_train = Var(shape=(spike_train_length,))\n",
    "        self.ground_truth_label = Var(shape=(1,))\n",
    "        self.v = Var(shape=(1,), init=0)\n",
    "        self.vth = Var(shape=(1,), init=vth)\n",
    "        \n",
    "@implements(proc=SpikeInput, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PySpikeInputModel(PyLoihiProcessModel):\n",
    "    # num_images: int = LavaPyType(int, int, precision=32)\n",
    "    num_spike_trains: int = LavaPyType(int, int, precision=32)\n",
    "    \n",
    "    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    label_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32,\n",
    "                                      precision=32)\n",
    "    \n",
    "    # num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    spike_train_length: int = LavaPyType(int, int, precision=32)\n",
    "    \n",
    "    # input_img: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    input_spike_train: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    \n",
    "    ground_truth_label: int = LavaPyType(int, int, precision=32)\n",
    "    v: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    vth: int = LavaPyType(int, int, precision=32)\n",
    "    \n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.curr_spike_train_id = 0\n",
    "\n",
    "    def post_guard(self):\n",
    "        \"\"\"Guard function for PostManagement phase.\n",
    "        \"\"\"\n",
    "        # self.time_step: global time\n",
    "        if self.time_step % self.spike_train_length == 1:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        \"\"\"Post-Management phase: executed only when guard function above \n",
    "        returns True.\n",
    "        \"\"\"\n",
    "        self.ground_truth_label = trainingData[self.curr_spike_train_id][1]\n",
    "        self.input_spike_train = trainingData[self.curr_spike_train_id][0].astype(np.int32)\n",
    "        self.v = np.zeros(self.v.shape)\n",
    "        self.label_out.send(np.array([self.ground_truth_label]))\n",
    "        self.curr_spike_train_id += 1\n",
    "\n",
    "    def run_spk(self):\n",
    "        \"\"\"Spiking phase: executed unconditionally at every time-step\n",
    "        \"\"\"\n",
    "        if self.time_step % 500 == 0:\n",
    "            print('.',end=\"\")\n",
    "        spike, self.input_spike_train = self.input_spike_train[0], self.input_spike_train[1:]\n",
    "        self.v[:] = self.v + spike\n",
    "        s_out = self.v > self.vth\n",
    "        self.v[s_out] = 0  # reset voltage to 0 after a spike\n",
    "        self.spikes_out.send(s_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.proc.monitor.process import Monitor\n",
    "from lava.magma.core.run_conditions import RunSteps, RunContinuous\n",
    "from lava.proc.lif.process import LIF\n",
    "\n",
    "num_steps = 3000 # 100 discrete time units\n",
    "run_condition = RunContinuous()\n",
    "run_condition = RunSteps(num_steps=num_steps)\n",
    "\n",
    "# lif1 = LIF(shape=(3, ),                         # Number and topological layout of units in the process\n",
    "#            vth=10.,                             # Membrane threshold\n",
    "#            dv=0.1,                              # Inverse membrane time-constant\n",
    "#            du=0.1,                              # Inverse synaptic time-constant\n",
    "#            bias_mant=(1.1, 1.2, 1.3),           # Bias added to the membrane voltage in every timestep\n",
    "#            name=\"lif1\")\n",
    "\n",
    "spike_input = SpikeInput(vth=1,\n",
    "                         num_spike_trains=len(trainingData))\n",
    "\n",
    "monitor_input = Monitor()\n",
    "monitor_input.probe(spike_input.v, num_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......"
     ]
    }
   ],
   "source": [
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "\n",
    "run_cfg = Loihi1SimCfg(select_tag=\"floating_pt\")\n",
    "spike_input.run(condition=run_condition, run_cfg=run_cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see 6 dots come out of this, means we ran for the right length of time. and below we should see a chart that shows the spikes coming out of the input neuron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Create a subplot for each monitor\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "ax0 = fig.add_subplot(121)\n",
    "\n",
    "# Plot the recorded data\n",
    "monitor_input.plot(ax0, spike_input.v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Lava-nc Tutorial</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Building a basic SNN with Lava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "import numpy as np\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.dense.process import Dense\n",
    "\n",
    "# LIF? use this to see params of LIF and some help  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense means all-all netowrk \n",
    "\n",
    "* lava works in terms of processes.\n",
    "    * runs asynchronously \n",
    "    * parallel \n",
    "    * communicates via Channels\n",
    "    * a process only defines the ports (i/o) and internal vars inital states not the behavior of the processes\n",
    "    \n",
    "![process.png](https://raw.githubusercontent.com/lava-nc/lava-docs/dev/walk-through-tutorial/_static/images/tutorial00/proc.png)\n",
    "\n",
    "Below both LIF and Dense are diffrent processes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processes\n",
    "lif1 = LIF(shape=(3, ),                         # Number and topological layout of units in the process\n",
    "           vth=10.,                             # Membrane threshold\n",
    "           dv=0.1,                              # Inverse membrane time-constant\n",
    "           du=0.1,                              # Inverse synaptic time-constant\n",
    "           bias_mant=(1.1, 1.2, 1.3),           # Bias added to the membrane voltage in every timestep\n",
    "           name=\"lif1\")\n",
    "\n",
    "dense = Dense(weights=np.random.rand(2, 3),     # Initial value of the weights, chosen randomly\n",
    "              name='dense')\n",
    "\n",
    "lif2 = LIF(shape=(2, ),                         # Number and topological layout of units in the process\n",
    "           vth=10.,                             # Membrane threshold\n",
    "           dv=0.1,                              # Inverse membrane time-constant\n",
    "           du=0.1,                              # Inverse synaptic time-constant\n",
    "           bias_mant=0.,                        # Bias added to the membrane voltage in every timestep\n",
    "           name='lif2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIF has one port in and one port out \n",
    "\n",
    "    * s_out => spike output\n",
    "    * a_in => activation in\n",
    "\n",
    "You can see i/o ports and internal valables, see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- LIF\")\n",
    "print(f\"lif ports out: {lif1.out_ports.member_names}\")\n",
    "print(f\"lif in ports: {lif1.in_ports.member_names}\")\n",
    "print(f\"internal lif vars: {lif1.vars.member_names}\") # see inrernal var names\n",
    "print(f\"internal lif var state: {lif1.v}\") # see current state of var\n",
    "print(\"--------------------------------------\")\n",
    "print()\n",
    "print(\"-- DENSE\")\n",
    "print(f\"dense ports out: {dense.out_ports.member_names}\")\n",
    "print(f\"dense in ports: {dense.in_ports.member_names}\")\n",
    "print(f\"internal dense vars: {dense.vars.member_names}\")\n",
    "print(f\"dense weights (init to random values): {dense.weights.get()}\")\n",
    "print(\"--------------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ports can only connect if thier shapes match to see the shape use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"LIF1 output dimension: {lif1.s_out.size}\")\n",
    "print(f\"DENSE input dimension: {dense.s_in.size}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have just created processes, we need to connect them. This is done by useing the <code>connect</code> method\n",
    "\n",
    "![process_comm.png](https://raw.githubusercontent.com/lava-nc/lava-docs/dev/walk-through-tutorial/_static/images/tutorial00/procs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the OutPort of lif1 to the InPort of dense\n",
    "lif1.s_out.connect(dense.s_in)\n",
    "\n",
    "# Connect the OutPort of dense to the InPort of lif2\n",
    "dense.a_out.connect(lif2.a_in)\n",
    "\n",
    "# NOTE: this python block should only be run once after you need to clear the varables to re-run it as processes can only be connected once "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to to run the network. This is done with the run function that takes two paramiters a <code>RunCondition</code> (how long) and a <code>RunConfig</code> (what hardware to run it on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.magma.core.run_conditions import RunSteps, RunContinuous\n",
    "num_steps = 100 # 100 discrete time units\n",
    "run_condition = RunContinuous()\n",
    "run_condition = RunSteps(num_steps=num_steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>RunConfig</code> defines on which hardware backend the network is executed.\n",
    "\n",
    "* Loihi1: <code>Loihi1HwCfg</code>\n",
    "* Loihi2: <code>Loihi2HwCfg</code>\n",
    "* Loihi1 simulated on CPU: <code>Loihi1SimCfg</code> \n",
    "* CPU: <code>floating_pt</code>\n",
    "\n",
    "The compiler and runtime then automatically select the correct <code>ProcessModels</code> such that the <code>RunConfig</code> can be fulfilled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "\n",
    "run_cfg = Loihi1SimCfg(select_tag=\"floating_pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running it is great! but we need to get data from it. To do that we need to setup monitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.proc.monitor.process import Monitor\n",
    "\n",
    "monitor_lif1 = Monitor()\n",
    "monitor_lif2 = Monitor()\n",
    "monitor_lif1.probe(lif1.v, num_steps)\n",
    "monitor_lif2.probe(lif2.v, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif2.run(condition=run_condition, run_cfg=run_cfg) # run it again with monitors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lif1 = monitor_lif1.get_data()\n",
    "data_lif2 = monitor_lif2.get_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor also has some plot methods that we can make good use of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Create a subplot for each monitor\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "ax0 = fig.add_subplot(121)\n",
    "ax1 = fig.add_subplot(122)\n",
    "\n",
    "# Plot the recorded data\n",
    "monitor_lif1.plot(ax0, lif1.v)\n",
    "monitor_lif2.plot(ax1, lif2.v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step we can stop the runtime by calling the `stop` function. `Stop` will terminate the `Runtime` and all states will be lost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif2.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we need is INPUT FROM A DATA SOURCE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Create a custom Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to read in data, a custome process must be created. That is data I/O is mustly supported via custom process. This part goes over how to create custom processes. The orignal tutorial makes a random <code>SpikeGenerator</code> but here we will follow this, then attempt to read in the spike trains in <code>Prepocessing/data/spikeTrains</code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import OutPort"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each custom processes must inherit from the <code>AbstractProcess</code> class. In our class we define \n",
    "\n",
    "* Vars\n",
    "* Input ports\n",
    "* Output ports\n",
    "\n",
    "For the random SpikeGenerator we will use a var to hold the probability of generating a spike and an output port. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeGenerator(AbstractProcess):\n",
    "    \"\"\"Spike generator process provides spikes to subsequent Processes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shape: tuple\n",
    "        defines the dimensionality of the generated spikes per timestep\n",
    "    spike_prob: int\n",
    "        spike probability in percent\n",
    "    \"\"\"\n",
    "    def __init__(self, shape: tuple, spike_prob: int) -> None:        \n",
    "        super().__init__()\n",
    "        self.spike_prob = Var(shape=(1, ), init=spike_prob)\n",
    "        self.s_out = OutPort(shape=shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that <code>OutPort</code> and <code>Var</code> are classes imported from lava.\n",
    "\n",
    "This class only defines the <code>Interface</code> of our custome process. To define the auctal logic we will need to add a <code>ProcessModels</code> to go with it. This will define the inner workings of our process. <i>ProcessModels can be found in the dedicated in-depth tutorials</i> ([here](https://github.com/lava-nc/lava/blob/main/tutorials/in_depth/tutorial03_process_models.ipynb) and [here](https://github.com/lava-nc/lava/blob/main/tutorials/in_depth/tutorial06_hierarchical_processes.ipynb)). Lava automatically selects the correct ProcessModel for each Process given the RunConfig.\n",
    "\n",
    "![process_models.png](https://raw.githubusercontent.com/lava-nc/lava-docs/dev/walk-through-tutorial/_static/images/tutorial00/proc_models.png)\n",
    "\n",
    "So in Summary our processes come in pairs of [Processes, ProcessModel] or [Interface, Logic]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will define our ProcessModel in python to be run on a CPU. All <code>ProcessModels</code> defined to run on CPU are written in Python and inherit from the common class called <code>PyLoihiProcessModel</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.magma.core.model.py.model import PyLoihiProcessModel # needed to define a CPU processes model\n",
    "from lava.magma.core.resources import CPU\n",
    "from lava.magma.core.decorator import implements, requires # decorators needed to define which computational resrouces are needed for our ProcessModel\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.model.py.type import LavaPyType # needed to define the internal vars of our model\n",
    "from lava.magma.core.model.py.ports import PyOutPort # needed to degfine the output port"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: </b> It is important to mention that the `ProcessModel` needs to implement the exact same Vars and Ports of the parent process using the same class attribute names."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our random SpikeGenertor model will follow the <code>LoihiProtocol</code> which defines phases for a neuron to run though. The main one is the <code>run_spk</code> and has 3 parts.\n",
    "\n",
    "1. Input spikes are receved \n",
    "2. Internal vars are updated \n",
    "3. Output spikes are sent\n",
    "\n",
    "There are other phases that can be added such as <i>learning phase</i> (run_lrn) where online learning can take place or <i>post management phase</i> (run_post_mgmt) in which memory content is updated. For our basic model we will only define the <code>run_spk</code> phase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need access to the global simulation time, this can be done with the <code>self.time_step</code> member. This is used to index the `spike_data` and send out the corresponding spikes through the `OutPort`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@implements(proc=SpikeGenerator, protocol=LoihiProtocol) # tells lava this model pairs with the SpikeGenerator interface and is using the LoihiProtocol (a.k.a the phases talked about above)\n",
    "@requires(CPU) # tells lava this uses the CPU \n",
    "class PySpikeGeneratorModel(PyLoihiProcessModel):\n",
    "    \"\"\"Spike Generator process model.\"\"\"\n",
    "    spike_prob: int = LavaPyType(int, int)\n",
    "    s_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, float)\n",
    "\n",
    "    def run_spk(self) -> None:\n",
    "        # Generate random spike data\n",
    "        spike_data = np.random.choice([0, 1], p=[1 - self.spike_prob/100, self.spike_prob/100], size=self.s_out.shape[0])\n",
    "        \n",
    "        # Send spikes\n",
    "        self.s_out.send(spike_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: </b> For the SpikeGenerator we only needed an OutPort which provides the <code>send</code> function to send data. For the <code>InPort</code> the corresponding function to receive data is called <code>recv</code>.\n",
    "\n",
    "* OutPort: uses <code>send</code> method\n",
    "* InPort: uses <code>recv</code> method\n",
    "\n",
    "<b>Note: </b> spike probablity is shared between all instance of this model and the outport from lava is shared as well, while the spike sent out are per neuron."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new network similar to the one before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processes\n",
    "lif1 = LIF(shape=(3, ),                         # Number of units in this process\n",
    "           vth=10.,                             # Membrane threshold\n",
    "           dv=0.1,                              # Inverse membrane time-constant\n",
    "           du=0.1,                              # Inverse synaptic time-constant\n",
    "           bias_mant=0.,                        # Bias added to the membrane voltage in every timestep\n",
    "           name=\"lif1\")\n",
    "\n",
    "dense = Dense(weights=np.random.rand(2, 3),     # Initial value of the weights, chosen randomly\n",
    "              name='dense')\n",
    "\n",
    "lif2 = LIF(shape=(2, ),                         # Number of units in this process\n",
    "           vth=5.,                             # Membrane threshold\n",
    "           dv=0.1,                              # Inverse membrane time-constant\n",
    "           du=0.1,                              # Inverse synaptic time-constant\n",
    "           bias_mant=0.,                        # Bias added to the membrane voltage in every timestep\n",
    "           name='lif2')\n",
    "\n",
    "# Connect the OutPort of lif1 to the InPort of dense\n",
    "lif1.s_out.connect(dense.s_in)\n",
    "\n",
    "# Connect the OutPort of dense to the InPort of lif2\n",
    "dense.a_out.connect(lif2.a_in)\n",
    "\n",
    "# Create Monitors to record membrane potentials\n",
    "monitor_lif1 = Monitor()\n",
    "monitor_lif2 = Monitor()\n",
    "monitor_lif2_outputSpikes = Monitor()\n",
    "\n",
    "# Probe membrane potentials from the two LIF populations\n",
    "monitor_lif1.probe(lif1.v, num_steps)\n",
    "monitor_lif2.probe(lif2.v, num_steps)\n",
    "monitor_lif2_outputSpikes.probe(lif2.s_out, num_steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add our new process random <code>SpikeGenerator</code> to the network. To connect it we go though a dense layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SpikeGenerator\n",
    "spike_gen = SpikeGenerator(shape=(lif1.a_in.shape[0], ), spike_prob=10) \n",
    " # neuron current = u[t] = u[t-1] * (1-du) + a_in so we want the output of SpikeGenerator to match the input of LIF a.k.a a_in.shape[0]\n",
    " # probablity as spike_prob/100 or as percent\n",
    " \n",
    " \n",
    "# Instantiate Dense\n",
    "dense_input = Dense(weights=np.eye(lif1.a_in.shape[0])) # one-to-one connectivity\n",
    "\n",
    "# Connect spike_gen to dense_input\n",
    "spike_gen.s_out.connect(dense_input.s_in) # SpikeGenerator.output => dense.input\n",
    "\n",
    "# Connect dense_input to LIF1 population\n",
    "dense_input.a_out.connect(lif1.a_in) # dense.output => LIF.input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Now we run it!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif2.run(condition=run_condition, run_cfg=run_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot for each monitor\n",
    "fig = plt.figure(figsize=(24, 10))\n",
    "ax0 = fig.add_subplot(121)\n",
    "# ax1 = fig.add_subplot(122)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "# Plot the recorded data\n",
    "monitor_lif1.plot(ax0, lif1.v) # vth=10 for both LIF1 and LIF2\n",
    "# monitor_lif2.plot(ax1, lif2.v)\n",
    "monitor_lif2_outputSpikes.plot(ax2, lif2.s_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif2.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# MNIST Digit Classification with Lava"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to make a SNN model composed of only dense and LIF layers. See the below figure \n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/lava-nc/lava-nc.github.io/main/_static/images/tutorial01/mnist_process_arch.png\" alt=\"MNIST Process AA\"\n",
    "style=\"width: 800px;\"/></center>\n",
    "\n",
    "The 3 Processes shown above are:\n",
    " - *SpikeInput* Process - generates spikes via integrate and fire dynamics,\n",
    " using the image input\n",
    " - *ImageClassifier* Process - encapsulates feed-forward architecture of\n",
    " Dense connectivity and LIF neurons\n",
    " - *Output* Process - accumulates output spikes from the feed-forward process\n",
    "and infers the class label\n",
    "\n",
    "> **Important Note**:\n",
    ">\n",
    "> The classifier is a simple feed-forward model using pre-trained network \n",
    "> parameters (weights and biases). It illustrates how to build, compile and \n",
    "> run a functional model in Lava. Please refer to \n",
    "> [Lava-DL](https://github.com/lava-nc/lava-dl) to understand how to train \n",
    "> deep networks with Lava."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "# general \n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import typing as ty\n",
    "\n",
    "# ploting\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# snn stuff\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.dense.process import Dense\n",
    "from lava.proc.monitor.process import Monitor\n",
    "from lava.magma.core.run_conditions import RunSteps, RunContinuous\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "\n",
    "# Import Process level primitives\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "\n",
    "# Import parent classes for ProcessModels\n",
    "from lava.magma.core.model.sub.model import AbstractSubProcessModel\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "\n",
    "# Import ProcessModel ports, data-types\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "\n",
    "# Import execution protocol and hardware resources\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.resources import CPU\n",
    "\n",
    "# Import decorators\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "\n",
    "# Import MNIST dataset\n",
    "from lava.utils.dataloader.mnist import MnistDataset\n",
    "np.set_printoptions(linewidth=np.inf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay the first processes os the spike input. We define the process then process model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process deinftion\n",
    "class SpikeInput(AbstractProcess):\n",
    "    \"\"\"Reads image data from the MNIST dataset and converts it to spikes.\n",
    "    The resulting spike rate is proportional to the pixel value.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vth: int,\n",
    "                 num_images: ty.Optional[int] = 25,\n",
    "                 num_steps_per_image: ty.Optional[int] = 128):\n",
    "        super().__init__()\n",
    "        shape = (784,)\n",
    "        self.spikes_out = OutPort(shape=shape)  # Input spikes to the classifier\n",
    "        self.label_out = OutPort(shape=(1,))  # Ground truth labels to OutputProc\n",
    "        self.num_images = Var(shape=(1,), init=num_images)\n",
    "        self.num_steps_per_image = Var(shape=(1,), init=num_steps_per_image)\n",
    "        self.input_img = Var(shape=shape)\n",
    "        self.ground_truth_label = Var(shape=(1,))\n",
    "        self.v = Var(shape=shape, init=0)\n",
    "        self.vth = Var(shape=(1,), init=vth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\_\\_init\\_\\_ \n",
    "In out process model we define a couple peaces to convert the images to spike trains. First in \\_\\_init\\_\\_ we setup out data loader <code>mnist_dataset</code> we initializ an image ID, starting from 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### post_guard\n",
    "For our post_guard we want to check if we are done reading an image. Sense these are still images we need to convert them to time series. num_steps_per_image basicly controls how long each image should \"play\", that is how long our spike trains are. The <code>post_guard</code> control when we are done with an image, that is when it's time series has ended."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run_post_mgmt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@implements(proc=SpikeInput, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PySpikeInputModel(PyLoihiProcessModel):\n",
    "    num_images: int = LavaPyType(int, int, precision=32)\n",
    "    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    label_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32,\n",
    "                                      precision=32)\n",
    "    num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    input_img: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    ground_truth_label: int = LavaPyType(int, int, precision=32)\n",
    "    v: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    vth: int = LavaPyType(int, int, precision=32)\n",
    "    \n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.mnist_dataset = MnistDataset()\n",
    "        self.curr_img_id = 0\n",
    "\n",
    "    def post_guard(self):\n",
    "        \"\"\"Guard function for PostManagement phase.\n",
    "        \"\"\"\n",
    "        if self.time_step % self.num_steps_per_image == 1:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        \"\"\"Post-Management phase: executed only when guard function above \n",
    "        returns True.\n",
    "        \"\"\"\n",
    "        img = self.mnist_dataset.images[self.curr_img_id]\n",
    "        self.ground_truth_label = self.mnist_dataset.labels[self.curr_img_id]\n",
    "        self.input_img = img.astype(np.int32) - 127\n",
    "        self.v = np.zeros(self.v.shape)\n",
    "        self.label_out.send(np.array([self.ground_truth_label]))\n",
    "        self.curr_img_id += 1\n",
    "\n",
    "    def run_spk(self):\n",
    "        \"\"\"Spiking phase: executed unconditionally at every time-step\n",
    "        \"\"\"\n",
    "        self.v[:] = self.v + self.input_img\n",
    "        s_out = self.v > self.vth\n",
    "        self.v[s_out] = 0  # reset voltage to 0 after a spike\n",
    "        self.spikes_out.send(s_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see if we can just see the input working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 25\n",
    "num_steps_per_image = 128\n",
    "\n",
    "# Create Process instances\n",
    "spike_input = SpikeInput(vth=1,\n",
    "                         num_images=num_images,\n",
    "                         num_steps_per_image=num_steps_per_image)\n",
    "\n",
    "# Create Monitors to record membrane potentials\n",
    "monitor_SpikeInput = Monitor()\n",
    "\n",
    "\n",
    "# Probe membrane potentials from the two LIF populations\n",
    "monitor_SpikeInput.probe(spike_input.spikes_out, num_steps_per_image)\n",
    "\n",
    "mnist_clf.run(\n",
    "    condition=RunSteps(num_steps=num_steps_per_image),\n",
    "    run_cfg=Loihi1SimCfg(select_sub_proc_model=True,\n",
    "                        select_tag='fixed_pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "366a53c283de3ac239fad2923e36904e6cb28c586fdc23988bad2bc80f7d8984"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
