{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import torch.multiprocessing as mp\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "from torch import nn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dnaDataloader import expermentDataloader\n",
    "from dnaDataloader import addData\n",
    "from scipy import stats as st\n",
    "from dnaModelUtil import train\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "batch_size = 25\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   mp.set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "   pass # throws error if run twice without resetting the kernal, if its already set we dont care that this errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval with small traing sets\n",
    "The goal here is to eval the model while training on small sets of data. That is how well can MLP learn from 100-200 examples of single-molecule experiments.\n",
    "A verity of samples have been provided anf preprocessed (converted from excel to csv and had empty frames added) to the folder <pre>/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [d[0] for d in os.walk(\"/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted\")][1:] # remove first one is it is \"/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted\"\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "featIn = 0\n",
    "for d in folders:\n",
    "    data = expermentDataloader(\n",
    "        f\"{d}/index.csv\",\n",
    "        f\"{d}\", \n",
    "    )\n",
    "    rawData = [d for d in data]\n",
    "    featIn = len(rawData[0][0])\n",
    "    trainValidData = []\n",
    "    testData = []\n",
    "    addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "\n",
    "    np.random.shuffle(trainValidData)\n",
    "    trainData = []\n",
    "    validData = []\n",
    "    addData(trainData, validData, trainValidData, rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "    datasets.append({\"name\": f\"{os.path.basename(d)}\", \n",
    "                     \"train\":DataLoader(trainData, batch_size=batch_size, shuffle=True) , \n",
    "                     \"valid\":DataLoader(validData, batch_size=batch_size, shuffle=True) , \n",
    "                     \"test\":DataLoader(testData, batch_size=len(testData), shuffle=True) ,\n",
    "                     \"model\": {}}\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets:\n",
      "{'name': '1800_nM_AR_out', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f87e3d26c50>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f87ee70e860>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd1bbfa0>, 'model': {}}\n",
      "{'name': '800_nM_AR_out', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f89480b0610>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd188850>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd188790>, 'model': {}}\n",
      "{'name': '1200_nM_AR_out', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f89480b3520>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd1d80d0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd213eb0>, 'model': {}}\n",
      "{'name': '400_nM_AR_out', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd1dadd0>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd210430>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd24bfa0>, 'model': {}}\n",
      "{'name': '50_nM_AR_out', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd213fa0>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd248340>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd07bfa0>, 'model': {}}\n",
      "{'name': '100_nM_AR_out', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd24beb0>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd0781c0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f87dd0b7d30>, 'model': {}}\n",
      "6\n",
      "featIn: 12000\n"
     ]
    }
   ],
   "source": [
    "print(f\"datasets:\")\n",
    "for d in datasets:\n",
    "    print(d)\n",
    "print(f\"{len(datasets)}\")\n",
    "print(f\"featIn: {featIn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 1800_nM_AR_out --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 800_nM_AR_out --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1200_nM_AR_out --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 400_nM_AR_out --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 50_nM_AR_out --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 100_nM_AR_out --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    print(f\"-- {d['name']} --\")\n",
    "    print(f\"train: {len(d['train'])}\")\n",
    "    print(f\"valid: {len(d['valid'])}\")\n",
    "    print(f\"test : {len(d['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = mp.Manager()\n",
    "return_dict = manager.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Process name='Process-2' parent=1560615 initial>,\n",
       " <Process name='Process-3' parent=1560615 initial>,\n",
       " <Process name='Process-4' parent=1560615 initial>,\n",
       " <Process name='Process-5' parent=1560615 initial>,\n",
       " <Process name='Process-6' parent=1560615 initial>,\n",
       " <Process name='Process-7' parent=1560615 initial>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processes = []\n",
    "devices = [torch.device(\"cuda:0\"),torch.device(\"cuda:1\"),torch.device(\"cuda:2\"),torch.device(\"cuda:3\")]\n",
    "epochs = 10000\n",
    "error_margin = 20\n",
    "for d in datasets:\n",
    "    processes.append(mp.Process(target=train, args=(d[\"train\"], d[\"valid\"], d[\"name\"], featIn, return_dict, epochs, error_margin, devices[0])))\n",
    "    devices.append(devices.pop(0))\n",
    "    \n",
    "processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1800_nM_AR_out on cuda:0...\n",
      "training 800_nM_AR_out on cuda:1...\n",
      "training 1200_nM_AR_out on cuda:2...\n",
      "training 400_nM_AR_out on cuda:3...\n"
     ]
    }
   ],
   "source": [
    "processesList = list(range(len(processes)))\n",
    "\n",
    "while processesList:\n",
    "    run = processesList[:4]\n",
    "    processesList = processesList[4:]\n",
    "    for i in run:\n",
    "        processes[i].start()\n",
    "    for i in run:\n",
    "        processes[i].join()\n",
    "        processes[i].terminate()\n",
    "print(return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict(return_dict)\n",
    "with open(\"./Models/smallTrain/results.json\", 'w') as file:\n",
    "    json_object = json.dumps(results, indent=4)\n",
    "    file.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
