{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dnaDataloader import expermentDataloader\n",
    "from dnaModelUtil import train\n",
    "from dnaModelUtil import RNNModel\n",
    "from dnaDataloader import addData\n",
    "from dnaDataloader import expermentDataloader\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "folder = '/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted/1800_nM_AR_5000'\n",
    "oneMinInFPS = 1200\n",
    "batch_size = 10\n",
    "num_workers = 0\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN running from 1 min to 30 min\n",
    "get reults under varied movie length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataset(oneTimeUnitInFPS:int, totalRuntime:int, folder:str, batch_size=10, num_workers = 0):\n",
    "    data = expermentDataloader(\n",
    "        f\"{folder}/index.csv\",\n",
    "        f\"{folder}\", \n",
    "        length = oneTimeUnitInFPS,\n",
    "    )\n",
    "    targets = [i[1] for i in data]\n",
    "    timeSlices = []\n",
    "    for startTime in range(0, totalRuntime, oneTimeUnitInFPS):\n",
    "        data = expermentDataloader(\n",
    "            f\"{folder}/index.csv\",\n",
    "            f\"{folder}\", \n",
    "            length = oneTimeUnitInFPS,\n",
    "            start=startTime\n",
    "        )\n",
    "        timeSlices.append([np.array(i[0]) for i in data])\n",
    "    rawInput = list(zip(*timeSlices))\n",
    "    rawInput = [np.array(i) for i in rawInput]\n",
    "    rawData =  list(zip(rawInput,targets))\n",
    "\n",
    "    trainValidData = []\n",
    "    testData = []\n",
    "    addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "\n",
    "    np.random.shuffle(trainValidData)\n",
    "    trainData = []\n",
    "    validData = []\n",
    "    addData(trainData, validData, trainValidData, rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "    trainDataset = DataLoader(trainData, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) \n",
    "    validDataset = DataLoader(validData, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    testDataset = DataLoader(testData, batch_size=len(testData), shuffle=True, num_workers=num_workers, pin_memory=True)  \n",
    "    \n",
    "    return (trainDataset, validDataset, testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training RNN_1_min on cuda:0...\n",
      "training RNN_2_min on cuda:0...       Train Loss:218.9880 Valid Loss:1965.9499\t           Train accuracy:0.8950 Valid accuracy:0.6600           \u001b\u001b\n",
      "training RNN_3_min on cuda:0...       Train Loss:174.0586 Valid Loss:2963.4140\t           Train accuracy:0.9200 Valid accuracy:0.5700           \u001b\u001b\n",
      "training RNN_4_min on cuda:0...       Train Loss:158.3613 Valid Loss:4685.1246\t           Train accuracy:0.9250 Valid accuracy:0.4000           \u001b\u001b\n",
      "training RNN_5_min on cuda:0...       Train Loss:192.4210 Valid Loss:3160.0571\t           Train accuracy:0.9000 Valid accuracy:0.5900           \u001b\u001b\n",
      "training RNN_6_min on cuda:0...       Train Loss:176.1591 Valid Loss:3535.1244\t           Train accuracy:0.9200 Valid accuracy:0.4900           \u001b\u001b\n",
      "training RNN_7_min on cuda:0...       Train Loss:127.2840 Valid Loss:3349.4044\t           Train accuracy:0.9250 Valid accuracy:0.5300           \u001b\u001b\n",
      "training RNN_8_min on cuda:0...       Train Loss:203.7654 Valid Loss:5088.2229\t           Train accuracy:0.9000 Valid accuracy:0.4700           \u001b\u001b\n",
      "training RNN_9_min on cuda:0...       Train Loss:142.7014 Valid Loss:2462.0954\t           Train accuracy:0.9250 Valid accuracy:0.5200           \u001b\u001b\n",
      "training RNN_10_min on cuda:0...      Train Loss:181.3251 Valid Loss:2579.7839\t           Train accuracy:0.9200 Valid accuracy:0.5700           \u001b\u001b\n",
      "training RNN_11_min on cuda:0...      Train Loss:150.2799 Valid Loss:4055.5340\t           Train accuracy:0.9350 Valid accuracy:0.4900           \u001b\u001b\n",
      "training RNN_12_min on cuda:0...      Train Loss:175.9833 Valid Loss:3403.9839\t           Train accuracy:0.9150 Valid accuracy:0.6100           \u001b\u001b\n",
      "training RNN_13_min on cuda:0...      Train Loss:216.6103 Valid Loss:4292.7124\t           Train accuracy:0.8900 Valid accuracy:0.4900           \u001b\u001b\n",
      "          epoch: 5424/7500\t           Train Loss:125.0031 Valid Loss:4078.7309\t           Train accuracy:0.9350 Valid accuracy:0.4714           \u001b\u001b\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m MSE \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss(reduction \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m adam \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(),lr\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m,weight_decay\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m train(trainData\u001b[39m=\u001b[39;49mtrainDataset, validData\u001b[39m=\u001b[39;49mvalidDataset, name\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRNN_\u001b[39;49m\u001b[39m{\u001b[39;49;00mtotalRuntime\u001b[39m}\u001b[39;49;00m\u001b[39m_min\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49mmodel, \n\u001b[1;32m     11\u001b[0m       lossfunction\u001b[39m=\u001b[39;49mMSE, optim\u001b[39m=\u001b[39;49madam, return_dict\u001b[39m=\u001b[39;49mrnn_return_dict, epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     12\u001b[0m       device\u001b[39m=\u001b[39;49mdevice, printStatus\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, savePath\u001b[39m=\u001b[39;49mmodelSavePath)\n",
      "File \u001b[0;32m~/GitHub/SNN-DNA-project/dnaModelUtil.py:46\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainData, validData, name, savePath, model, lossfunction, optim, return_dict, epochs, margin_of_error, device, printStatus)\u001b[0m\n\u001b[1;32m     44\u001b[0m loss \u001b[39m=\u001b[39m lossfunction(outputs, targets)\n\u001b[1;32m     45\u001b[0m avgLoss\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(loss\u001b[39m.\u001b[39mclone()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()))\n\u001b[0;32m---> 46\u001b[0m totalCorrect \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39;49misclose(outputs\u001b[39m.\u001b[39;49mint(), targets\u001b[39m.\u001b[39;49mint(), atol\u001b[39m=\u001b[39;49mmargin_of_error))\n\u001b[1;32m     47\u001b[0m totalCorrect \u001b[39m=\u001b[39m totalCorrect\u001b[39m.\u001b[39mclone()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     48\u001b[0m currentAcc\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(totalCorrect\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(targets)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn_return_dict = {}\n",
    "featIn = oneMinInFPS\n",
    "epochs = 7500\n",
    "modelSavePath = \"./Models/variedMovie/\"\n",
    "for totalRuntime in range(1,31):\n",
    "      trainDataset, validDataset, testDataset = makeDataset(oneMinInFPS, totalRuntime, folder)\n",
    "      model = RNNModel(featIn=oneMinInFPS, capacity=int(featIn*0.25), hiddenLayers=4).to(device)\n",
    "      MSE = nn.MSELoss(reduction = 'mean')\n",
    "      adam = torch.optim.Adam(model.parameters(),lr=0.00001,weight_decay=1e-5)\n",
    "      train(trainData=trainDataset, validData=validDataset, name=f\"RNN_{totalRuntime}_min\", model=model, \n",
    "            lossfunction=MSE, optim=adam, return_dict=rnn_return_dict, epochs=epochs,\n",
    "            device=device, printStatus=True, savePath=modelSavePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_return_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
