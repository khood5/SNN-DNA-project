{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import torch.multiprocessing as mp\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "from torch import nn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dnaDataloader import expermentDataloader\n",
    "from dnaDataloader import addData\n",
    "from scipy import stats as st\n",
    "from dnaModelUtil import train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "   mp.set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "   pass # throws error if run twice without resetting the kernal, if its already set we dont care that this errors\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "# num_workers = 25\n",
    "batch_size = 25\n",
    "num_workers = 0\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval with small traing sets\n",
    "The goal here is to eval the model while training on small sets of data. That is how well can MLP learn from 100-200 examples of single-molecule experiments.\n",
    "A verity of samples have been provided anf preprocessed (converted from excel to csv and had empty frames added) to the folder <pre>/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [d[0] for d in os.walk(\"/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted\")][1:] # remove first one is it is \"/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted\"\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "featIn = 0\n",
    "for d in folders:\n",
    "    data = expermentDataloader(\n",
    "        f\"{d}/index.csv\",\n",
    "        f\"{d}\", \n",
    "    )\n",
    "    rawData = [d for d in data]\n",
    "    featIn = len(rawData[0][0])\n",
    "    trainValidData = []\n",
    "    testData = []\n",
    "    addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "\n",
    "    np.random.shuffle(trainValidData)\n",
    "    trainData = []\n",
    "    validData = []\n",
    "    addData(trainData, validData, trainValidData, rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "    datasets.append({\"name\": f\"{os.path.basename(d)}\", \n",
    "                     \"train\":DataLoader(trainData, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) , \n",
    "                     \"valid\":DataLoader(validData, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) , \n",
    "                     \"test\":DataLoader(testData, batch_size=len(testData), shuffle=True, num_workers=num_workers, pin_memory=True) ,\n",
    "                     \"featIn\": featIn,\n",
    "                     \"model\": {}}\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets:\n",
      "{'name': '1800_nM_AR_2100', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f0409f711e0>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f06287087f0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03ff3d7c10>, 'featIn': 42000, 'model': {}}\n",
      "{'name': '800_nM_AR_1200', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f06318c1690>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03ff415c00>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03ff3efc70>, 'featIn': 24000, 'model': {}}\n",
      "{'name': '100_nM_AR_2100', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03ff418250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03ff40b100>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03ff40bf10>, 'featIn': 42000, 'model': {}}\n",
      "{'name': '400_nM_AR_2400', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03ff40ae90>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f89fbfa0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f89fbe80>, 'featIn': 48000, 'model': {}}\n",
      "{'name': '400_nM_AR_1800', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8a04250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8a23e80>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8a20220>, 'featIn': 36000, 'model': {}}\n",
      "{'name': '1200_nM_AR_1200', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8a88370>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8a60d00>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8a60970>, 'featIn': 24000, 'model': {}}\n",
      "{'name': '400_nM_AR_900', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8a60940>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8aa3fa0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8aa3e80>, 'featIn': 18000, 'model': {}}\n",
      "{'name': '1200_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8804250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8ac8460>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8a6bd60>, 'featIn': 12000, 'model': {}}\n",
      "{'name': '100_nM_AR_900', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8af4250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f88534f0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f88530d0>, 'featIn': 18000, 'model': {}}\n",
      "{'name': '1800_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8664250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8697d60>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8852d10>, 'featIn': 12000, 'model': {}}\n",
      "{'name': '1800_nM_AR_2400', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f86c4070>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f86b00d0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f86b3e80>, 'featIn': 48000, 'model': {}}\n",
      "{'name': '1200_nM_AR_1800', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8874250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f86b81f0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f86b0a60>, 'featIn': 36000, 'model': {}}\n",
      "{'name': '1800_nM_AR_1800', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f3c18250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8867f40>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8865000>, 'featIn': 36000, 'model': {}}\n",
      "{'name': '50_nM_AR_1200', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f3c08250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f3c33910>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f3c338b0>, 'featIn': 24000, 'model': {}}\n",
      "{'name': '100_nM_AR_1200', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f86dff10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f3c5ff40>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f3c5fa00>, 'featIn': 24000, 'model': {}}\n",
      "{'name': '50_nM_AR_2400', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f850ff10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f3c855a0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f3c85540>, 'featIn': 48000, 'model': {}}\n",
      "{'name': '100_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8478250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f85b3f10>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8525090>, 'featIn': 12000, 'model': {}}\n",
      "{'name': '1800_nM_AR_1200', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f84dff10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f84c41f0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f84c4910>, 'featIn': 24000, 'model': {}}\n",
      "{'name': '400_nM_AR_1500', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8a14250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f859ae30>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f859be80>, 'featIn': 30000, 'model': {}}\n",
      "{'name': '800_nM_AR_900', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f859ab90>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8577e80>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8574a30>, 'featIn': 18000, 'model': {}}\n",
      "{'name': '50_nM_AR_900', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f853c250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8558220>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f855be80>, 'featIn': 18000, 'model': {}}\n",
      "{'name': '400_nM_AR_2100', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8547f10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8304190>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8307f10>, 'featIn': 42000, 'model': {}}\n",
      "{'name': '100_nM_AR_2400', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8307100>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8334fa0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8334250>, 'featIn': 48000, 'model': {}}\n",
      "{'name': '1800_nM_AR_1500', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8388250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f834b5b0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8334df0>, 'featIn': 30000, 'model': {}}\n",
      "{'name': '50_nM_AR_1500', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f83b8250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f83a2050>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f83a3f40>, 'featIn': 30000, 'model': {}}\n",
      "{'name': '1800_nM_AR_900', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f83f0130>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f83d1bd0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f83d3e80>, 'featIn': 18000, 'model': {}}\n",
      "{'name': '800_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f819c2e0>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f81cc2e0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f83d1480>, 'featIn': 12000, 'model': {}}\n",
      "{'name': '400_nM_AR_1200', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f820fd00>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f81e8160>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f81e9630>, 'featIn': 24000, 'model': {}}\n",
      "{'name': '1200_nM_AR_1500', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f826ff10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f828bf10>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f81f7160>, 'featIn': 30000, 'model': {}}\n",
      "{'name': '1200_nM_AR_2400', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8233f10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03f82549d0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8254940>, 'featIn': 48000, 'model': {}}\n",
      "{'name': '50_nM_AR_2100', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03c326ff10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03c325ff10>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03c325e830>, 'featIn': 42000, 'model': {}}\n",
      "{'name': '1200_nM_AR_900', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03c32a7f10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03c3286380>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03c3287f40>, 'featIn': 18000, 'model': {}}\n",
      "{'name': '800_nM_AR_2400', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8293f10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03c32c3b20>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03c32c3e80>, 'featIn': 48000, 'model': {}}\n",
      "{'name': '800_nM_AR_1500', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03c3303f10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03c32e2380>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03c32e2590>, 'featIn': 30000, 'model': {}}\n",
      "{'name': '50_nM_AR_1800', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03c333bf10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03c3319210>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03c331bf10>, 'featIn': 36000, 'model': {}}\n",
      "{'name': '800_nM_AR_2100', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03c3318f10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f0367b90b80>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f0367b90c40>, 'featIn': 42000, 'model': {}}\n",
      "{'name': '100_nM_AR_1800', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f0367bb8250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f0367ba7c40>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f0367ba7ee0>, 'featIn': 36000, 'model': {}}\n",
      "{'name': '1200_nM_AR_2100', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f0367bf4070>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f0367bd0100>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f0367bd3e80>, 'featIn': 42000, 'model': {}}\n",
      "{'name': '800_nM_AR_1800', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f0367bdc250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f0367c132b0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f0367c134c0>, 'featIn': 36000, 'model': {}}\n",
      "{'name': '400_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f0333734250>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03109a8250>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f0367c13100>, 'featIn': 12000, 'model': {}}\n",
      "{'name': '100_nM_AR_1500', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f03f8a4bf10>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f03109c6fb0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f03109c4040>, 'featIn': 30000, 'model': {}}\n",
      "{'name': '50_nM_AR_600', 'train': <torch.utils.data.dataloader.DataLoader object at 0x7f02f1810040>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7f0310a34250>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f0333664070>, 'featIn': 12000, 'model': {}}\n",
      "42\n",
      "featIn: 12000\n"
     ]
    }
   ],
   "source": [
    "print(f\"datasets:\")\n",
    "for d in datasets:\n",
    "    print(d)\n",
    "print(f\"{len(datasets)}\")\n",
    "print(f\"featIn: {featIn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 1800_nM_AR_2100 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 800_nM_AR_1200 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 100_nM_AR_2100 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 400_nM_AR_2400 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 400_nM_AR_1800 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1200_nM_AR_1200 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 400_nM_AR_900 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1200_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 100_nM_AR_900 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1800_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1800_nM_AR_2400 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1200_nM_AR_1800 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1800_nM_AR_1800 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 50_nM_AR_1200 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 100_nM_AR_1200 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 50_nM_AR_2400 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 100_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1800_nM_AR_1200 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 400_nM_AR_1500 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 800_nM_AR_900 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 50_nM_AR_900 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 400_nM_AR_2100 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 100_nM_AR_2400 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1800_nM_AR_1500 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 50_nM_AR_1500 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1800_nM_AR_900 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 800_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 400_nM_AR_1200 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1200_nM_AR_1500 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1200_nM_AR_2400 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 50_nM_AR_2100 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1200_nM_AR_900 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 800_nM_AR_2400 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 800_nM_AR_1500 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 50_nM_AR_1800 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 800_nM_AR_2100 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 100_nM_AR_1800 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 1200_nM_AR_2100 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 800_nM_AR_1800 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 400_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 100_nM_AR_1500 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n",
      "-- 50_nM_AR_600 --\n",
      "train: 8\n",
      "valid: 4\n",
      "test : 1\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    print(f\"-- {d['name']} --\")\n",
    "    print(f\"train: {len(d['train'])}\")\n",
    "    print(f\"valid: {len(d['valid'])}\")\n",
    "    print(f\"test : {len(d['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '1800_nM_AR_2100',\n",
       " 'train': <torch.utils.data.dataloader.DataLoader at 0x7f0409f711e0>,\n",
       " 'valid': <torch.utils.data.dataloader.DataLoader at 0x7f06287087f0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f03ff3d7c10>,\n",
       " 'featIn': 42000,\n",
       " 'model': {}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = mp.Manager()\n",
    "return_dict = manager.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '100_nM_AR_900',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8af4250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f88534f0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f88530d0>,\n",
       "  'featIn': 18000,\n",
       "  'model': {}},\n",
       " {'name': '1800_nM_AR_2100',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f0409f711e0>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f06287087f0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03ff3d7c10>,\n",
       "  'featIn': 42000,\n",
       "  'model': {}},\n",
       " {'name': '800_nM_AR_1200',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f06318c1690>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03ff415c00>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03ff3efc70>,\n",
       "  'featIn': 24000,\n",
       "  'model': {}},\n",
       " {'name': '100_nM_AR_2100',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03ff418250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03ff40b100>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03ff40bf10>,\n",
       "  'featIn': 42000,\n",
       "  'model': {}},\n",
       " {'name': '400_nM_AR_2400',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03ff40ae90>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f89fbfa0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f89fbe80>,\n",
       "  'featIn': 48000,\n",
       "  'model': {}},\n",
       " {'name': '400_nM_AR_1800',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8a04250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f8a23e80>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f8a20220>,\n",
       "  'featIn': 36000,\n",
       "  'model': {}},\n",
       " {'name': '1200_nM_AR_1200',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8a88370>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f8a60d00>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f8a60970>,\n",
       "  'featIn': 24000,\n",
       "  'model': {}},\n",
       " {'name': '400_nM_AR_900',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8a60940>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f8aa3fa0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f8aa3e80>,\n",
       "  'featIn': 18000,\n",
       "  'model': {}},\n",
       " {'name': '1200_nM_AR_600',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8804250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f8ac8460>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f8a6bd60>,\n",
       "  'featIn': 12000,\n",
       "  'model': {}},\n",
       " {'name': '1800_nM_AR_2400',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f86c4070>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f86b00d0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f86b3e80>,\n",
       "  'featIn': 48000,\n",
       "  'model': {}},\n",
       " {'name': '1200_nM_AR_1800',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8874250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f86b81f0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f86b0a60>,\n",
       "  'featIn': 36000,\n",
       "  'model': {}},\n",
       " {'name': '1800_nM_AR_1800',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f3c18250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f8867f40>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f8865000>,\n",
       "  'featIn': 36000,\n",
       "  'model': {}},\n",
       " {'name': '50_nM_AR_1200',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f3c08250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f3c33910>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f3c338b0>,\n",
       "  'featIn': 24000,\n",
       "  'model': {}},\n",
       " {'name': '100_nM_AR_1200',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f86dff10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f3c5ff40>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f3c5fa00>,\n",
       "  'featIn': 24000,\n",
       "  'model': {}},\n",
       " {'name': '50_nM_AR_2400',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f850ff10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f3c855a0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f3c85540>,\n",
       "  'featIn': 48000,\n",
       "  'model': {}},\n",
       " {'name': '100_nM_AR_600',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8478250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f85b3f10>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f8525090>,\n",
       "  'featIn': 12000,\n",
       "  'model': {}},\n",
       " {'name': '1800_nM_AR_1200',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f84dff10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f84c41f0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f84c4910>,\n",
       "  'featIn': 24000,\n",
       "  'model': {}},\n",
       " {'name': '400_nM_AR_1500',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8a14250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f859ae30>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f859be80>,\n",
       "  'featIn': 30000,\n",
       "  'model': {}},\n",
       " {'name': '800_nM_AR_900',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f859ab90>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f8577e80>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f8574a30>,\n",
       "  'featIn': 18000,\n",
       "  'model': {}},\n",
       " {'name': '50_nM_AR_900',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f853c250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f8558220>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f855be80>,\n",
       "  'featIn': 18000,\n",
       "  'model': {}},\n",
       " {'name': '400_nM_AR_2100',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8547f10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f8304190>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f8307f10>,\n",
       "  'featIn': 42000,\n",
       "  'model': {}},\n",
       " {'name': '100_nM_AR_2400',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8307100>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f8334fa0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f8334250>,\n",
       "  'featIn': 48000,\n",
       "  'model': {}},\n",
       " {'name': '1800_nM_AR_1500',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8388250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f834b5b0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f8334df0>,\n",
       "  'featIn': 30000,\n",
       "  'model': {}},\n",
       " {'name': '50_nM_AR_1500',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f83b8250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f83a2050>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f83a3f40>,\n",
       "  'featIn': 30000,\n",
       "  'model': {}},\n",
       " {'name': '1800_nM_AR_900',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f83f0130>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f83d1bd0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f83d3e80>,\n",
       "  'featIn': 18000,\n",
       "  'model': {}},\n",
       " {'name': '800_nM_AR_600',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f819c2e0>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f81cc2e0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f83d1480>,\n",
       "  'featIn': 12000,\n",
       "  'model': {}},\n",
       " {'name': '400_nM_AR_1200',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f820fd00>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f81e8160>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f81e9630>,\n",
       "  'featIn': 24000,\n",
       "  'model': {}},\n",
       " {'name': '1200_nM_AR_1500',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f826ff10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f828bf10>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f81f7160>,\n",
       "  'featIn': 30000,\n",
       "  'model': {}},\n",
       " {'name': '1200_nM_AR_2400',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8233f10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03f82549d0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03f8254940>,\n",
       "  'featIn': 48000,\n",
       "  'model': {}},\n",
       " {'name': '50_nM_AR_2100',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03c326ff10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03c325ff10>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03c325e830>,\n",
       "  'featIn': 42000,\n",
       "  'model': {}},\n",
       " {'name': '1200_nM_AR_900',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03c32a7f10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03c3286380>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03c3287f40>,\n",
       "  'featIn': 18000,\n",
       "  'model': {}},\n",
       " {'name': '800_nM_AR_2400',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8293f10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03c32c3b20>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03c32c3e80>,\n",
       "  'featIn': 48000,\n",
       "  'model': {}},\n",
       " {'name': '800_nM_AR_1500',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03c3303f10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03c32e2380>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03c32e2590>,\n",
       "  'featIn': 30000,\n",
       "  'model': {}},\n",
       " {'name': '50_nM_AR_1800',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03c333bf10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03c3319210>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03c331bf10>,\n",
       "  'featIn': 36000,\n",
       "  'model': {}},\n",
       " {'name': '800_nM_AR_2100',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03c3318f10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f0367b90b80>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f0367b90c40>,\n",
       "  'featIn': 42000,\n",
       "  'model': {}},\n",
       " {'name': '100_nM_AR_1800',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f0367bb8250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f0367ba7c40>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f0367ba7ee0>,\n",
       "  'featIn': 36000,\n",
       "  'model': {}},\n",
       " {'name': '1200_nM_AR_2100',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f0367bf4070>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f0367bd0100>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f0367bd3e80>,\n",
       "  'featIn': 42000,\n",
       "  'model': {}},\n",
       " {'name': '800_nM_AR_1800',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f0367bdc250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f0367c132b0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f0367c134c0>,\n",
       "  'featIn': 36000,\n",
       "  'model': {}},\n",
       " {'name': '400_nM_AR_600',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f0333734250>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03109a8250>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f0367c13100>,\n",
       "  'featIn': 12000,\n",
       "  'model': {}},\n",
       " {'name': '100_nM_AR_1500',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f03f8a4bf10>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f03109c6fb0>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f03109c4040>,\n",
       "  'featIn': 30000,\n",
       "  'model': {}},\n",
       " {'name': '50_nM_AR_600',\n",
       "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f02f1810040>,\n",
       "  'valid': <torch.utils.data.dataloader.DataLoader at 0x7f0310a34250>,\n",
       "  'test': <torch.utils.data.dataloader.DataLoader at 0x7f0333664070>,\n",
       "  'featIn': 12000,\n",
       "  'model': {}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [datasets.pop(8)] + datasets[:8] + datasets[9:]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Process name='Process-2' parent=815690 initial>,\n",
       " <Process name='Process-3' parent=815690 initial>,\n",
       " <Process name='Process-4' parent=815690 initial>,\n",
       " <Process name='Process-5' parent=815690 initial>,\n",
       " <Process name='Process-6' parent=815690 initial>,\n",
       " <Process name='Process-7' parent=815690 initial>,\n",
       " <Process name='Process-8' parent=815690 initial>,\n",
       " <Process name='Process-9' parent=815690 initial>,\n",
       " <Process name='Process-10' parent=815690 initial>,\n",
       " <Process name='Process-11' parent=815690 initial>,\n",
       " <Process name='Process-12' parent=815690 initial>,\n",
       " <Process name='Process-13' parent=815690 initial>,\n",
       " <Process name='Process-14' parent=815690 initial>,\n",
       " <Process name='Process-15' parent=815690 initial>,\n",
       " <Process name='Process-16' parent=815690 initial>,\n",
       " <Process name='Process-17' parent=815690 initial>,\n",
       " <Process name='Process-18' parent=815690 initial>,\n",
       " <Process name='Process-19' parent=815690 initial>,\n",
       " <Process name='Process-20' parent=815690 initial>,\n",
       " <Process name='Process-21' parent=815690 initial>,\n",
       " <Process name='Process-22' parent=815690 initial>,\n",
       " <Process name='Process-23' parent=815690 initial>,\n",
       " <Process name='Process-24' parent=815690 initial>,\n",
       " <Process name='Process-25' parent=815690 initial>,\n",
       " <Process name='Process-26' parent=815690 initial>,\n",
       " <Process name='Process-27' parent=815690 initial>,\n",
       " <Process name='Process-28' parent=815690 initial>,\n",
       " <Process name='Process-29' parent=815690 initial>,\n",
       " <Process name='Process-30' parent=815690 initial>,\n",
       " <Process name='Process-31' parent=815690 initial>,\n",
       " <Process name='Process-32' parent=815690 initial>,\n",
       " <Process name='Process-33' parent=815690 initial>,\n",
       " <Process name='Process-34' parent=815690 initial>,\n",
       " <Process name='Process-35' parent=815690 initial>,\n",
       " <Process name='Process-36' parent=815690 initial>,\n",
       " <Process name='Process-37' parent=815690 initial>,\n",
       " <Process name='Process-38' parent=815690 initial>,\n",
       " <Process name='Process-39' parent=815690 initial>,\n",
       " <Process name='Process-40' parent=815690 initial>,\n",
       " <Process name='Process-41' parent=815690 initial>,\n",
       " <Process name='Process-42' parent=815690 initial>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processes = []\n",
    "devices = [torch.device(\"cuda:0\"),torch.device(\"cuda:1\"),torch.device(\"cuda:2\"),torch.device(\"cuda:3\")]\n",
    "epochs = 5000\n",
    "error_margin = 20\n",
    "for d in datasets:\n",
    "    # try:\n",
    "    #     train(d[\"train\"], d[\"valid\"], d[\"name\"], d[\"featIn\"], return_dict, epochs, error_margin, devices[0], capacity=int(d[\"name\"].split('_')[-1]) )\n",
    "    # except:\n",
    "    #     print(\"skipping \" + d[\"name\"])\n",
    "    processes.append(mp.Process(target=train, args=(d[\"train\"], d[\"valid\"], d[\"name\"], d[\"featIn\"], return_dict, epochs, error_margin, devices[0])))\n",
    "    devices.append(devices.pop(0))\n",
    "    \n",
    "processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in return_dict:\n",
    "    print(f\"{return_dict[k]['path'].split('/')[-1]}: {return_dict[k]['acc']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 100_nM_AR_900 on cuda:0...\n",
      "training 1800_nM_AR_2100 on cuda:1...\n",
      "training 800_nM_AR_1200 on cuda:2...\n",
      "training 100_nM_AR_2100 on cuda:3...\n",
      "training 400_nM_AR_2400 on cuda:0...\n",
      "training 400_nM_AR_1800 on cuda:1...\n",
      "training 1200_nM_AR_1200 on cuda:2...\n",
      "training 400_nM_AR_900 on cuda:3...\n",
      "training 1200_nM_AR_600 on cuda:0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/khood/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 34, in train\n",
      "    for i, (inputs, targets) in enumerate(trainData):\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 171, in collate_numpy_array_fn\n",
      "    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "RuntimeError: stack expects each tensor to be equal size, but got [42000] at entry 0 and [18000] at entry 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1800_nM_AR_2400 on cuda:1...\n",
      "training 1200_nM_AR_1800 on cuda:2...\n",
      "training 1800_nM_AR_1800 on cuda:3...\n",
      "training 50_nM_AR_1200 on cuda:0...\n",
      "training 100_nM_AR_1200 on cuda:1...\n",
      "training 50_nM_AR_2400 on cuda:2...\n",
      "training 100_nM_AR_600 on cuda:3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/khood/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 34, in train\n",
      "    for i, (inputs, targets) in enumerate(trainData):\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 171, in collate_numpy_array_fn\n",
      "    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "RuntimeError: stack expects each tensor to be equal size, but got [12000] at entry 0 and [36000] at entry 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1800_nM_AR_1200 on cuda:0...\n",
      "training 400_nM_AR_1500 on cuda:1...\n",
      "training 800_nM_AR_900 on cuda:2...\n",
      "training 50_nM_AR_900 on cuda:3...\n",
      "training 400_nM_AR_2100 on cuda:0...\n",
      "training 100_nM_AR_2400 on cuda:1...\n",
      "training 1800_nM_AR_1500 on cuda:2...\n",
      "training 50_nM_AR_1500 on cuda:3...\n",
      "training 1800_nM_AR_900 on cuda:0...\n",
      "training 800_nM_AR_600 on cuda:1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/khood/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 34, in train\n",
      "    for i, (inputs, targets) in enumerate(trainData):\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 171, in collate_numpy_array_fn\n",
      "    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "RuntimeError: stack expects each tensor to be equal size, but got [24000] at entry 0 and [36000] at entry 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 400_nM_AR_1200 on cuda:2...\n",
      "training 1200_nM_AR_1500 on cuda:3...\n",
      "training 1200_nM_AR_2400 on cuda:0...\n",
      "training 50_nM_AR_2100 on cuda:1...\n",
      "training 1200_nM_AR_900 on cuda:2...\n",
      "training 800_nM_AR_2400 on cuda:3...\n",
      "training 800_nM_AR_1500 on cuda:0...\n",
      "training 50_nM_AR_1800 on cuda:1...\n",
      "training 800_nM_AR_2100 on cuda:2...\n",
      "training 100_nM_AR_1800 on cuda:3...\n",
      "training 1200_nM_AR_2100 on cuda:0...\n",
      "training 800_nM_AR_1800 on cuda:1...\n",
      "training 400_nM_AR_600 on cuda:2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-40:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/khood/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 34, in train\n",
      "    for i, (inputs, targets) in enumerate(trainData):\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 171, in collate_numpy_array_fn\n",
      "    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "RuntimeError: stack expects each tensor to be equal size, but got [12000] at entry 0 and [30000] at entry 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 100_nM_AR_1500 on cuda:3...\n",
      "training 50_nM_AR_600 on cuda:0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-42:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/khood/GitHub/SNN-DNA-project/dnaModelUtil.py\", line 34, in train\n",
      "    for i, (inputs, targets) in enumerate(trainData):\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 171, in collate_numpy_array_fn\n",
      "    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/khood/anaconda3/envs/torchbenchmark/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "RuntimeError: stack expects each tensor to be equal size, but got [24000] at entry 0 and [30000] at entry 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'100_nM_AR_900': {'path': './Models/smallTrain/100_nM_AR_900.pt', 'acc': 0.29000000000000004}, '1800_nM_AR_2100': {'path': './Models/smallTrain/1800_nM_AR_2100.pt', 'acc': 0.09000000000000001}, '800_nM_AR_1200': {'path': './Models/smallTrain/800_nM_AR_1200.pt', 'acc': 0.05}, '100_nM_AR_2100': {'path': './Models/smallTrain/100_nM_AR_2100.pt', 'acc': 0.02}, '400_nM_AR_2400': {'path': './Models/smallTrain/400_nM_AR_2400.pt', 'acc': 0.0}, '400_nM_AR_1800': {'path': './Models/smallTrain/400_nM_AR_1800.pt', 'acc': 0.01}, '1200_nM_AR_1200': {'path': './Models/smallTrain/1200_nM_AR_1200.pt', 'acc': 0.28}, '400_nM_AR_900': {'path': './Models/smallTrain/400_nM_AR_900.pt', 'acc': 0.2}, '1800_nM_AR_2400': {'path': './Models/smallTrain/1800_nM_AR_2400.pt', 'acc': 0.07}, '1200_nM_AR_1800': {'path': './Models/smallTrain/1200_nM_AR_1800.pt', 'acc': 0.05}, '1800_nM_AR_1800': {'path': './Models/smallTrain/1800_nM_AR_1800.pt', 'acc': 0.08}, '50_nM_AR_1200': {'path': './Models/smallTrain/50_nM_AR_1200.pt', 'acc': 0.5700000000000001}, '100_nM_AR_1200': {'path': './Models/smallTrain/100_nM_AR_1200.pt', 'acc': 0.15000000000000002}, '50_nM_AR_2400': {'path': './Models/smallTrain/50_nM_AR_2400.pt', 'acc': 0.09000000000000001}, '1800_nM_AR_1200': {'path': './Models/smallTrain/1800_nM_AR_1200.pt', 'acc': 0.26}, '400_nM_AR_1500': {'path': './Models/smallTrain/400_nM_AR_1500.pt', 'acc': 0.04}, '800_nM_AR_900': {'path': './Models/smallTrain/800_nM_AR_900.pt', 'acc': 0.2}, '50_nM_AR_900': {'path': './Models/smallTrain/50_nM_AR_900.pt', 'acc': 0.67}, '400_nM_AR_2100': {'path': './Models/smallTrain/400_nM_AR_2100.pt', 'acc': 0.01}, '100_nM_AR_2400': {'path': './Models/smallTrain/100_nM_AR_2400.pt', 'acc': 0.01}, '1800_nM_AR_1500': {'path': './Models/smallTrain/1800_nM_AR_1500.pt', 'acc': 0.2}, '50_nM_AR_1500': {'path': './Models/smallTrain/50_nM_AR_1500.pt', 'acc': 0.53}, '1800_nM_AR_900': {'path': './Models/smallTrain/1800_nM_AR_900.pt', 'acc': 0.26}, '400_nM_AR_1200': {'path': './Models/smallTrain/400_nM_AR_1200.pt', 'acc': 0.21000000000000002}, '1200_nM_AR_1500': {'path': './Models/smallTrain/1200_nM_AR_1500.pt', 'acc': 0.2}, '1200_nM_AR_2400': {'path': './Models/smallTrain/1200_nM_AR_2400.pt', 'acc': 0.05}, '50_nM_AR_2100': {'path': './Models/smallTrain/50_nM_AR_2100.pt', 'acc': 0.15000000000000002}, '1200_nM_AR_900': {'path': './Models/smallTrain/1200_nM_AR_900.pt', 'acc': 0.27}, '800_nM_AR_2400': {'path': './Models/smallTrain/800_nM_AR_2400.pt', 'acc': 0.0}, '800_nM_AR_1500': {'path': './Models/smallTrain/800_nM_AR_1500.pt', 'acc': 0.01}, '50_nM_AR_1800': {'path': './Models/smallTrain/50_nM_AR_1800.pt', 'acc': 0.27}, '800_nM_AR_2100': {'path': './Models/smallTrain/800_nM_AR_2100.pt', 'acc': 0.0}, '100_nM_AR_1800': {'path': './Models/smallTrain/100_nM_AR_1800.pt', 'acc': 0.03}, '1200_nM_AR_2100': {'path': './Models/smallTrain/1200_nM_AR_2100.pt', 'acc': 0.07}, '800_nM_AR_1800': {'path': './Models/smallTrain/800_nM_AR_1800.pt', 'acc': 0.01}, '100_nM_AR_1500': {'path': './Models/smallTrain/100_nM_AR_1500.pt', 'acc': 0.04}}\n"
     ]
    }
   ],
   "source": [
    "processesList = list(range(len(processes)))\n",
    "\n",
    "while processesList:\n",
    "    run = processesList[:4]\n",
    "    processesList = processesList[4:]\n",
    "    for i in run:\n",
    "        processes[i].start()\n",
    "    for i in run:\n",
    "        processes[i].join()\n",
    "        processes[i].terminate()\n",
    "print(return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict(return_dict)\n",
    "with open(\"./Models/smallTrain/results.json\", 'w') as file:\n",
    "    json_object = json.dumps(results, indent=4)\n",
    "    file.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
