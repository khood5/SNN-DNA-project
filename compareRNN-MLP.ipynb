{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch\n",
    "import copy\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from dnaDataloader import expermentDataloader\n",
    "import os\n",
    "import random\n",
    "import matplotlib.colors as mcolors\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from dnaModelUtil import printStats\n",
    "from dnaModelUtil import train\n",
    "from dnaModelUtil import RNNModel\n",
    "from dnaDataloader import addData\n",
    "from dnaDataloader import expermentDataloader\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from torchsummary import summary\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "oneMinInFPS = 1200\n",
    "batch_size = 10\n",
    "num_workers = 0\n",
    "movieRuntime = 5\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneTimeUnitInFPS = oneMinInFPS\n",
    "totalRuntime = movieRuntime*oneMinInFPS\n",
    "folder = '/home/khood/GitHub/SNN-DNA-project/Prepocessing/sorted/1800_nM_AR_5000'\n",
    "def makeDataset(oneTimeUnitInFPS:int, totalRuntime:int, folder:str, batch_size=10, num_workers = 0):\n",
    "    data = expermentDataloader(\n",
    "        f\"{folder}/index.csv\",\n",
    "        f\"{folder}\", \n",
    "        length = oneTimeUnitInFPS,\n",
    "    )\n",
    "    targets = [i[1] for i in data]\n",
    "    timeSlices = []\n",
    "    for startTime in range(0, totalRuntime, oneTimeUnitInFPS):\n",
    "        data = expermentDataloader(\n",
    "            f\"{folder}/index.csv\",\n",
    "            f\"{folder}\", \n",
    "            length = oneTimeUnitInFPS,\n",
    "            start=startTime\n",
    "        )\n",
    "        timeSlices.append([np.array(i[0]) for i in data])\n",
    "    rawInput = list(zip(*timeSlices))\n",
    "    rawInput = [np.array(i) for i in rawInput]\n",
    "    rawData =  list(zip(rawInput,targets))\n",
    "\n",
    "    trainValidData = []\n",
    "    testData = []\n",
    "    addData(testData, trainValidData, rawData, rhsSize=300)\n",
    "\n",
    "\n",
    "    np.random.shuffle(trainValidData)\n",
    "    trainData = []\n",
    "    validData = []\n",
    "    addData(trainData, validData, trainValidData, rhsSize=int(len(trainValidData)*(1/3)))\n",
    "\n",
    "    trainDataset = DataLoader(trainData, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) \n",
    "    validDataset = DataLoader(validData, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    testDataset = DataLoader(testData, batch_size=len(testData), shuffle=True, num_workers=num_workers, pin_memory=True)  \n",
    "    \n",
    "    return (trainDataset, validDataset, testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset, validDataset, testDataset = makeDataset(oneTimeUnitInFPS, totalRuntime, folder)\n",
    "print(f\"number train batches:{len(trainDataset)}\")\n",
    "print(f\"number valid batches:{len(validDataset)}\")\n",
    "print(f\"number test batches:{len(testDataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict = {}\n",
    "featIn = oneTimeUnitInFPS\n",
    "epochs = 1000\n",
    "em = 20\n",
    "for totalRuntime in range(1,30):\n",
    "      trainDataset, validDataset, testDataset = makeDataset(oneTimeUnitInFPS, totalRuntime, folder)\n",
    "      model = RNNModel(featIn=oneTimeUnitInFPS, capacity=int(featIn*0.25), hiddenLayers=4).to(device)\n",
    "      MSE = nn.MSELoss(reduction = 'mean')\n",
    "      adam = torch.optim.Adam(model.parameters(),lr=0.00001,weight_decay=1e-5)\n",
    "      train(trainData=trainDataset, validData=validDataset, name=f\"RNN_{totalRuntime}_min\", model=model, \n",
    "            lossfunction=MSE, optim=adam, return_dict=return_dict, epochs=epochs,\n",
    "            margin_of_error=em, device=device, printStatus=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
